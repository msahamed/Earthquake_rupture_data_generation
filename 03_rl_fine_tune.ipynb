{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import gym\n",
    "from stable_baselines3 import PPO, A2C, DQN, SAC, TD3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "random_state = 6\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (1600, 9) and test data shape (400, 9)\n"
     ]
    }
   ],
   "source": [
    "## look data with pandas\n",
    "train_file = \"data/rupturemodel_train.txt\"\n",
    "val_file = \"data/rupturemodel_validate.txt\"\n",
    "test_file = \"data/rupturemodel_test.txt\"\n",
    "\n",
    "df_train= pd.read_csv(train_file, sep=\" \", header = None)\n",
    "df_val= pd.read_csv(val_file, sep=\" \", header = None)\n",
    "df_test= pd.read_csv(test_file, sep=\" \", header = None)\n",
    "\n",
    "columns =  ['height', 'width', 'sxx', 'sxy', 'syy', 'sdrop', 'mud', 'dc', 'label']\n",
    "df_train.columns = columns\n",
    "df_val.columns = columns\n",
    "df_test.columns = columns\n",
    "\n",
    "frames = [df_train, df_val]\n",
    "df_train = pd.concat(frames)\n",
    "print('train data shape {} and test data shape {}'.format(np.shape(df_train), np.shape(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_new = df.copy()\n",
    "    # Create new features\n",
    "    df_new['height_width_ratio'] = df_new['height'] / df_new['width']\n",
    "    df_new['normal_stress_diff'] = df_new['sxx'] - df_new['syy']\n",
    "    df_new['friction_product'] = df_new['mud'] * (df_new['sdrop'])\n",
    "    df_new['stress_ratio'] = df_new['sxy'] / df_new['syy']\n",
    "    df_new['static_dynamic_friction_diff'] = (\n",
    "        df_new['mud'] + df_new['sdrop']) - df_new['mud']\n",
    "    df_new['stress_diff_dynamic_strength'] = df_new['sxy'] - \\\n",
    "        (df_new['syy'] * df_new['mud'])\n",
    "    df_new['normalized_dc'] = df_new['dc'] / df_new['width']\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data/rupturemodel_train.txt\"\n",
    "columns = ['height', 'width', 'sxx', 'sxy',\n",
    "           'syy', 'sdrop', 'mud', 'dc', 'label']\n",
    "df_train = pd.read_csv(train_file, sep=\" \", header=None)\n",
    "df_train.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "g_input_dim = 100\n",
    "g_output_dim = 8\n",
    "generator = Generator(g_input_dim, g_output_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your reinforcement learning environment\n",
    "class GeneratorEnv(gym.Env):\n",
    "    def __init__(self, generator_model, supervised_model):\n",
    "        super(GeneratorEnv, self).__init__()\n",
    "        self.generator_model = generator_model.to(device)\n",
    "        self.supervised_model = supervised_model\n",
    "        self.generator_input_size = 100\n",
    "        self.scaler = joblib.load('./models/scaler.pkl')\n",
    "        self.state = torch.randn(100).to(device)\n",
    "        self.action_space = gym.spaces.Box( low = 0, high = 1, shape = (8,), dtype = np.float32)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(100,), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.state = torch.randn(1, self.generator_input_size).to(device)\n",
    "        self.generator_model.eval()\n",
    "        output = self.generator_model(self.state)\n",
    "        processed_data = self.process_for_supervised_model(\n",
    "            output.squeeze(0).detach().cpu())\n",
    "        reward = self.supervised_model.predict(processed_data)\n",
    "        done = False\n",
    "        info = {}\n",
    "        return self.state.cpu().numpy(), reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = torch.randn(100).to(device)\n",
    "        return self.state.cpu().numpy()\n",
    "\n",
    "    def process_for_supervised_model(self, generated_data: torch.Tensor) -> np.array:\n",
    "        # Process the generated data to make it compatible with the supervised model\n",
    "        columns = ['height', 'width', 'sxx',\n",
    "                   'sxy', 'syy', 'sdrop', 'mud', 'dc']\n",
    "        generated_data = generated_data.numpy()\n",
    "        de_normalized = self.scaler.inverse_transform(\n",
    "            generated_data.reshape(1, -1))  # Reshape to a 2D array\n",
    "        df = pd.DataFrame(de_normalized, columns=columns)\n",
    "        df = create_new_features(df)\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 8  # Modify this value based on your generator's input dimension\n",
    "output_dim = input_dim  # Modify this value based on your generator's output dimension\n",
    "# Load the generator and supervised models\n",
    "generator_model = torch.load('./models/best_generator.pth').to(device)\n",
    "supervised_model = lgb.Booster(model_file='./models/best_supervised_model.txt')\n",
    "# Create the custom environment\n",
    "env = DummyVecEnv([lambda: GeneratorEnv(generator_model, supervised_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (100,) into shape (100,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/sabber/Documents/Research/Machine_learning/Earthquake_rupture/03_rl_fine_tune.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sabber/Documents/Research/Machine_learning/Earthquake_rupture/03_rl_fine_tune.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the generator using PPO\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sabber/Documents/Research/Machine_learning/Earthquake_rupture/03_rl_fine_tune.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m PPO(\u001b[39m'\u001b[39m\u001b[39mMlpPolicy\u001b[39m\u001b[39m'\u001b[39m, env, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, tensorboard_log\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./logs/rl_logs/\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sabber/Documents/Research/Machine_learning/Earthquake_rupture/03_rl_fine_tune.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m200000\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py:308\u001b[0m, in \u001b[0;36mPPO.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[39mself\u001b[39m: SelfPPO,\n\u001b[1;32m    301\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    307\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfPPO:\n\u001b[0;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[1;32m    309\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[1;32m    310\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[1;32m    311\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[1;32m    312\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[1;32m    313\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[1;32m    314\u001b[0m         progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m    315\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py:239\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[1;32m    230\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    236\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m SelfOnPolicyAlgorithm:\n\u001b[1;32m    237\u001b[0m     iteration \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 239\u001b[0m     total_timesteps, callback \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_learn(\n\u001b[1;32m    240\u001b[0m         total_timesteps,\n\u001b[1;32m    241\u001b[0m         callback,\n\u001b[1;32m    242\u001b[0m         reset_num_timesteps,\n\u001b[1;32m    243\u001b[0m         tb_log_name,\n\u001b[1;32m    244\u001b[0m         progress_bar,\n\u001b[1;32m    245\u001b[0m     )\n\u001b[1;32m    247\u001b[0m     callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[1;32m    249\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:412\u001b[0m, in \u001b[0;36mBaseAlgorithm._setup_learn\u001b[0;34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m# Avoid resetting the environment when calling ``.learn()`` consecutive times\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39mif\u001b[39;00m reset_num_timesteps \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 412\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mreset()  \u001b[39m# pytype: disable=annotation-type-mismatch\u001b[39;00m\n\u001b[1;32m    413\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_episode_starts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mnum_envs,), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m    414\u001b[0m     \u001b[39m# Retrieve unnormalized observation for saving into the buffer\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:75\u001b[0m, in \u001b[0;36mDummyVecEnv.reset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m     74\u001b[0m     obs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menvs[env_idx]\u001b[39m.\u001b[39mreset()\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_obs(env_idx, obs)\n\u001b[1;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obs_from_buf()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:105\u001b[0m, in \u001b[0;36mDummyVecEnv._save_obs\u001b[0;34m(self, env_idx, obs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys:\n\u001b[1;32m    104\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_obs[key][env_idx] \u001b[39m=\u001b[39m obs\n\u001b[1;32m    106\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_obs[key][env_idx] \u001b[39m=\u001b[39m obs[key]\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (100,) into shape (100,1)"
     ]
    }
   ],
   "source": [
    "# Train the generator using PPO\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=\"./logs/rl_logs/\")\n",
    "model.learn(total_timesteps=200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the model with environment\n",
    "model_name = 'rl_model_pp0_generator'\n",
    "model.save(f'./models/{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model\n",
    "loaded_model = PPO.load(f'./models/{model_name}')\n",
    "loaded_env = model.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_array = []\n",
    "generated_data = []\n",
    "obs = loaded_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = loaded_env.step(action)\n",
    "    generated_data.append(list(action[0]))\n",
    "    rewards_array.append(rewards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the generated data to make it compatible with the supervised model\n",
    "scaler = joblib.load('./models/scaler.pkl')\n",
    "def process_for_supervised_model(generated_data):\n",
    "    # Process the generated data to make it compatible with the supervised model\n",
    "    columns = ['height', 'width', 'sxx',\n",
    "               'sxy', 'syy', 'sdrop', 'mud', 'dc']\n",
    "    de_normalized = scaler.inverse_transform(generated_data)  # Reshape to a 2D array\n",
    "    df = pd.DataFrame(de_normalized, columns=columns)\n",
    "    df = create_new_features(df)\n",
    "    return df\n",
    "\n",
    "data = np.array(generated_data)\n",
    "df_generated = process_for_supervised_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>sxx</th>\n",
       "      <th>sxy</th>\n",
       "      <th>syy</th>\n",
       "      <th>sdrop</th>\n",
       "      <th>mud</th>\n",
       "      <th>dc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.071747</td>\n",
       "      <td>1.492561</td>\n",
       "      <td>-85.727744</td>\n",
       "      <td>35.405536</td>\n",
       "      <td>-85.295950</td>\n",
       "      <td>0.390677</td>\n",
       "      <td>0.306744</td>\n",
       "      <td>0.401653</td>\n",
       "      <td>0.356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.046195</td>\n",
       "      <td>0.289699</td>\n",
       "      <td>45.301701</td>\n",
       "      <td>20.402395</td>\n",
       "      <td>42.617577</td>\n",
       "      <td>0.112238</td>\n",
       "      <td>0.088545</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.479055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-196.579802</td>\n",
       "      <td>2.491208</td>\n",
       "      <td>-159.945235</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.254480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.030697</td>\n",
       "      <td>1.246860</td>\n",
       "      <td>-120.756137</td>\n",
       "      <td>19.565099</td>\n",
       "      <td>-121.961244</td>\n",
       "      <td>0.292298</td>\n",
       "      <td>0.233558</td>\n",
       "      <td>0.369119</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.068957</td>\n",
       "      <td>1.480246</td>\n",
       "      <td>-83.074266</td>\n",
       "      <td>32.316379</td>\n",
       "      <td>-86.022800</td>\n",
       "      <td>0.387075</td>\n",
       "      <td>0.285329</td>\n",
       "      <td>0.400085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.105718</td>\n",
       "      <td>1.739429</td>\n",
       "      <td>-48.382402</td>\n",
       "      <td>49.338103</td>\n",
       "      <td>-48.805945</td>\n",
       "      <td>0.482003</td>\n",
       "      <td>0.357936</td>\n",
       "      <td>0.434763</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.195712</td>\n",
       "      <td>2.085240</td>\n",
       "      <td>-7.933036</td>\n",
       "      <td>97.528776</td>\n",
       "      <td>-10.044879</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height        width          sxx          sxy          syy  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.071747     1.492561   -85.727744    35.405536   -85.295950   \n",
       "std       0.046195     0.289699    45.301701    20.402395    42.617577   \n",
       "min       0.000070     1.000214  -196.579802     2.491208  -159.945235   \n",
       "25%       0.030697     1.246860  -120.756137    19.565099  -121.961244   \n",
       "50%       0.068957     1.480246   -83.074266    32.316379   -86.022800   \n",
       "75%       0.105718     1.739429   -48.382402    49.338103   -48.805945   \n",
       "max       0.195712     2.085240    -7.933036    97.528776   -10.044879   \n",
       "\n",
       "             sdrop          mud           dc        label  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.390677     0.306744     0.401653     0.356000  \n",
       "std       0.112238     0.088545     0.051051     0.479055  \n",
       "min       0.200579     0.200045     0.254480     0.000000  \n",
       "25%       0.292298     0.233558     0.369119     0.000000  \n",
       "50%       0.387075     0.285329     0.400085     0.000000  \n",
       "75%       0.482003     0.357936     0.434763     1.000000  \n",
       "max       0.599913     0.573047     0.583352     1.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>sxx</th>\n",
       "      <th>sxy</th>\n",
       "      <th>syy</th>\n",
       "      <th>sdrop</th>\n",
       "      <th>mud</th>\n",
       "      <th>dc</th>\n",
       "      <th>height_width_ratio</th>\n",
       "      <th>normal_stress_diff</th>\n",
       "      <th>friction_product</th>\n",
       "      <th>stress_ratio</th>\n",
       "      <th>static_dynamic_friction_diff</th>\n",
       "      <th>stress_diff_dynamic_strength</th>\n",
       "      <th>normalized_dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.063394</td>\n",
       "      <td>1.296227</td>\n",
       "      <td>-137.108780</td>\n",
       "      <td>36.248058</td>\n",
       "      <td>-110.833115</td>\n",
       "      <td>0.331662</td>\n",
       "      <td>0.324279</td>\n",
       "      <td>0.354454</td>\n",
       "      <td>0.051309</td>\n",
       "      <td>-26.276779</td>\n",
       "      <td>0.108106</td>\n",
       "      <td>-0.901348</td>\n",
       "      <td>0.331662</td>\n",
       "      <td>72.316261</td>\n",
       "      <td>0.294753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.079161</td>\n",
       "      <td>0.427622</td>\n",
       "      <td>77.197952</td>\n",
       "      <td>40.059795</td>\n",
       "      <td>58.650623</td>\n",
       "      <td>0.161480</td>\n",
       "      <td>0.153558</td>\n",
       "      <td>0.143669</td>\n",
       "      <td>0.067623</td>\n",
       "      <td>93.132484</td>\n",
       "      <td>0.078602</td>\n",
       "      <td>2.035063</td>\n",
       "      <td>0.161480</td>\n",
       "      <td>46.748653</td>\n",
       "      <td>0.139064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>2.388038</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.233045</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-188.631592</td>\n",
       "      <td>0.040125</td>\n",
       "      <td>-9.750129</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>4.390887</td>\n",
       "      <td>0.109466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>2.388038</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.233045</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-81.143330</td>\n",
       "      <td>0.042511</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>34.384281</td>\n",
       "      <td>0.228989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001201</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>9.043187</td>\n",
       "      <td>-147.081818</td>\n",
       "      <td>0.213705</td>\n",
       "      <td>0.205554</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.090970</td>\n",
       "      <td>-0.232437</td>\n",
       "      <td>0.213705</td>\n",
       "      <td>67.792137</td>\n",
       "      <td>0.232995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.141214</td>\n",
       "      <td>1.563697</td>\n",
       "      <td>-63.473439</td>\n",
       "      <td>82.603052</td>\n",
       "      <td>-59.375022</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>0.484058</td>\n",
       "      <td>0.497733</td>\n",
       "      <td>0.093977</td>\n",
       "      <td>28.048768</td>\n",
       "      <td>0.120010</td>\n",
       "      <td>-0.017088</td>\n",
       "      <td>0.484021</td>\n",
       "      <td>103.581730</td>\n",
       "      <td>0.368533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.195712</td>\n",
       "      <td>2.128935</td>\n",
       "      <td>-7.933036</td>\n",
       "      <td>97.618210</td>\n",
       "      <td>-10.011992</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.195670</td>\n",
       "      <td>152.012192</td>\n",
       "      <td>0.343778</td>\n",
       "      <td>-0.014930</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height        width          sxx          sxy          syy  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.063394     1.296227  -137.108780    36.248058  -110.833115   \n",
       "std       0.079161     0.427622    77.197952    40.059795    58.650623   \n",
       "min       0.000003     1.000214  -198.643585     2.388038  -159.945221   \n",
       "25%       0.000003     1.000214  -198.643585     2.388038  -159.945221   \n",
       "50%       0.001201     1.000214  -198.643585     9.043187  -147.081818   \n",
       "75%       0.141214     1.563697   -63.473439    82.603052   -59.375022   \n",
       "max       0.195712     2.128935    -7.933036    97.618210   -10.011992   \n",
       "\n",
       "             sdrop          mud           dc  height_width_ratio  \\\n",
       "count  1000.000000  1000.000000  1000.000000         1000.000000   \n",
       "mean      0.331662     0.324279     0.354454            0.051309   \n",
       "std       0.161480     0.153558     0.143669            0.067623   \n",
       "min       0.200579     0.200045     0.233045            0.000001   \n",
       "25%       0.200579     0.200045     0.233045            0.000003   \n",
       "50%       0.213705     0.205554     0.259465            0.000991   \n",
       "75%       0.484021     0.484058     0.497733            0.093977   \n",
       "max       0.599913     0.573047     0.583352            0.195670   \n",
       "\n",
       "       normal_stress_diff  friction_product  stress_ratio  \\\n",
       "count         1000.000000       1000.000000   1000.000000   \n",
       "mean           -26.276779          0.108106     -0.901348   \n",
       "std             93.132484          0.078602      2.035063   \n",
       "min           -188.631592          0.040125     -9.750129   \n",
       "25%            -81.143330          0.042511     -0.610323   \n",
       "50%            -38.698364          0.090970     -0.232437   \n",
       "75%             28.048768          0.120010     -0.017088   \n",
       "max            152.012192          0.343778     -0.014930   \n",
       "\n",
       "       static_dynamic_friction_diff  stress_diff_dynamic_strength  \\\n",
       "count                   1000.000000                   1000.000000   \n",
       "mean                       0.331662                     72.316261   \n",
       "std                        0.161480                     46.748653   \n",
       "min                        0.200579                      4.390887   \n",
       "25%                        0.200579                     34.384281   \n",
       "50%                        0.213705                     67.792137   \n",
       "75%                        0.484021                    103.581730   \n",
       "max                        0.599913                    189.274338   \n",
       "\n",
       "       normalized_dc  \n",
       "count    1000.000000  \n",
       "mean        0.294753  \n",
       "std         0.139064  \n",
       "min         0.109466  \n",
       "25%         0.228989  \n",
       "50%         0.232995  \n",
       "75%         0.368533  \n",
       "max         0.583227  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>sxx</th>\n",
       "      <th>sxy</th>\n",
       "      <th>syy</th>\n",
       "      <th>sdrop</th>\n",
       "      <th>mud</th>\n",
       "      <th>dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.171282</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>2.388038</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.306040</td>\n",
       "      <td>0.206193</td>\n",
       "      <td>0.271141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.555410</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>36.584038</td>\n",
       "      <td>-10.011992</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.278166</td>\n",
       "      <td>0.348336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-142.781708</td>\n",
       "      <td>32.800877</td>\n",
       "      <td>-95.948616</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.233045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.955054</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>94.455864</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.583352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>2.388038</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.583352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.054781</td>\n",
       "      <td>2.128935</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>60.208935</td>\n",
       "      <td>-66.395500</td>\n",
       "      <td>0.535698</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.233045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.151725</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.618210</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.315802</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.464034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.146542</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.618210</td>\n",
       "      <td>-55.660603</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.233045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.128935</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>2.388038</td>\n",
       "      <td>-139.108246</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.360395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.195712</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-7.933036</td>\n",
       "      <td>2.388038</td>\n",
       "      <td>-10.011992</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.569919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       height     width         sxx        sxy         syy     sdrop  \\\n",
       "48   0.171282  1.000214 -198.643585   2.388038 -159.945221  0.306040   \n",
       "703  0.000003  1.555410 -198.643585  36.584038  -10.011992  0.599913   \n",
       "282  0.000003  1.000214 -142.781708  32.800877  -95.948616  0.200579   \n",
       "112  0.000003  1.955054 -198.643585  94.455864 -159.945221  0.599913   \n",
       "920  0.000003  1.000214 -198.643585   2.388038 -159.945221  0.599913   \n",
       "46   0.054781  2.128935 -198.643585  60.208935  -66.395500  0.535698   \n",
       "391  0.000003  1.151725 -198.643585  97.618210 -159.945221  0.315802   \n",
       "107  0.146542  1.000214 -198.643585  97.618210  -55.660603  0.200579   \n",
       "316  0.000003  2.128935 -198.643585   2.388038 -139.108246  0.200579   \n",
       "142  0.195712  1.000214   -7.933036   2.388038  -10.011992  0.200579   \n",
       "\n",
       "          mud        dc  \n",
       "48   0.206193  0.271141  \n",
       "703  0.278166  0.348336  \n",
       "282  0.200045  0.233045  \n",
       "112  0.200045  0.583352  \n",
       "920  0.200045  0.583352  \n",
       "46   0.573047  0.233045  \n",
       "391  0.200045  0.464034  \n",
       "107  0.573047  0.233045  \n",
       "316  0.200045  0.360395  \n",
       "142  0.200045  0.569919  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_columns = ['height', 'width', 'sxx',\n",
    "           'sxy', 'syy', 'sdrop', 'mud', 'dc']\n",
    "df_generated[train_columns].sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.676064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.303125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.231509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.493496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.727863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.903609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.323363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reward\n",
       "count  1000.000000\n",
       "mean      0.676064\n",
       "std       0.303125\n",
       "min      -0.231509\n",
       "25%       0.493496\n",
       "50%       0.727863\n",
       "75%       0.903609\n",
       "max       1.323363"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rewards = pd.DataFrame(rewards_array, columns=['reward'])\n",
    "df_rewards.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-b19dda306396410ab79254daf3aec86f\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-b19dda306396410ab79254daf3aec86f\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-b19dda306396410ab79254daf3aec86f\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-f9d98faa3de18aeccce1f898c2f770a3\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"bin\": {\"maxbins\": 100}, \"field\": \"reward\", \"type\": \"quantitative\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"height\": 400, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-f9d98faa3de18aeccce1f898c2f770a3\": [{\"reward\": 0.6834846138954163}, {\"reward\": 0.1030803918838501}, {\"reward\": 0.4911649525165558}, {\"reward\": -0.0388423427939415}, {\"reward\": 1.0330698490142822}, {\"reward\": 0.6844567656517029}, {\"reward\": 1.062393307685852}, {\"reward\": 0.5642296075820923}, {\"reward\": 0.6070970296859741}, {\"reward\": 0.7930967807769775}, {\"reward\": 0.807314395904541}, {\"reward\": 0.22086256742477417}, {\"reward\": 0.9471672177314758}, {\"reward\": 0.38940155506134033}, {\"reward\": 0.8042200803756714}, {\"reward\": 0.6723536252975464}, {\"reward\": 0.9734881520271301}, {\"reward\": 0.16995210945606232}, {\"reward\": 0.6318585276603699}, {\"reward\": 0.7100903391838074}, {\"reward\": 0.541485607624054}, {\"reward\": 0.9831913709640503}, {\"reward\": 0.9397578835487366}, {\"reward\": 1.093222975730896}, {\"reward\": 0.30206337571144104}, {\"reward\": 1.0211182832717896}, {\"reward\": 0.7051030993461609}, {\"reward\": 0.9428340196609497}, {\"reward\": 0.10051318258047104}, {\"reward\": 0.4885108768939972}, {\"reward\": 0.8239951729774475}, {\"reward\": 0.6333540081977844}, {\"reward\": 0.9712331295013428}, {\"reward\": 1.0167359113693237}, {\"reward\": 0.6979541182518005}, {\"reward\": 0.9055553674697876}, {\"reward\": 0.7126473188400269}, {\"reward\": 0.5573143362998962}, {\"reward\": 0.6059445142745972}, {\"reward\": 1.189871907234192}, {\"reward\": 0.9066594839096069}, {\"reward\": 0.3389818072319031}, {\"reward\": 0.8552802205085754}, {\"reward\": 0.7688247561454773}, {\"reward\": 0.6165804266929626}, {\"reward\": 0.6000916361808777}, {\"reward\": 0.9118192791938782}, {\"reward\": 0.4980488717556}, {\"reward\": 0.3009985387325287}, {\"reward\": 0.1449880748987198}, {\"reward\": 0.7818518280982971}, {\"reward\": 0.3705354630947113}, {\"reward\": 0.4532686471939087}, {\"reward\": 0.8107668161392212}, {\"reward\": 0.4411933422088623}, {\"reward\": 0.9554277658462524}, {\"reward\": 0.727657675743103}, {\"reward\": 0.4463135898113251}, {\"reward\": 1.0196176767349243}, {\"reward\": 0.5549165606498718}, {\"reward\": 0.999320924282074}, {\"reward\": 0.6123349070549011}, {\"reward\": 0.7361010313034058}, {\"reward\": 0.8618592023849487}, {\"reward\": 0.0878770649433136}, {\"reward\": 0.8539702296257019}, {\"reward\": 0.26132556796073914}, {\"reward\": 0.8095053434371948}, {\"reward\": 0.9920127391815186}, {\"reward\": 0.5779354572296143}, {\"reward\": 0.523672878742218}, {\"reward\": 0.3725321292877197}, {\"reward\": 0.2658868134021759}, {\"reward\": 0.9537186026573181}, {\"reward\": 0.7229663133621216}, {\"reward\": 0.8935368061065674}, {\"reward\": 0.6100561618804932}, {\"reward\": 0.9549978971481323}, {\"reward\": 0.830658495426178}, {\"reward\": 1.1501022577285767}, {\"reward\": 0.9202084541320801}, {\"reward\": 0.12956325709819794}, {\"reward\": 0.7209790349006653}, {\"reward\": 0.44824036955833435}, {\"reward\": 0.2043515294790268}, {\"reward\": 0.4000149667263031}, {\"reward\": 0.6933277249336243}, {\"reward\": 0.8142527937889099}, {\"reward\": 0.6858323812484741}, {\"reward\": 0.4613041579723358}, {\"reward\": 0.7280689477920532}, {\"reward\": 0.2282097339630127}, {\"reward\": 1.02449631690979}, {\"reward\": 0.7140205502510071}, {\"reward\": 0.6813608407974243}, {\"reward\": 0.6403502821922302}, {\"reward\": 0.7877422571182251}, {\"reward\": 0.5313943028450012}, {\"reward\": 0.4933824837207794}, {\"reward\": 0.9846097230911255}, {\"reward\": 0.4086321294307709}, {\"reward\": 0.37501823902130127}, {\"reward\": 0.3469350337982178}, {\"reward\": 0.5295077562332153}, {\"reward\": 0.5036773681640625}, {\"reward\": 1.0965453386306763}, {\"reward\": 0.9569176435470581}, {\"reward\": 0.8332341909408569}, {\"reward\": 0.5395126938819885}, {\"reward\": 0.6754096150398254}, {\"reward\": 0.2660655677318573}, {\"reward\": 0.5310881733894348}, {\"reward\": 0.30114632844924927}, {\"reward\": 0.6967223286628723}, {\"reward\": 1.1358449459075928}, {\"reward\": 0.15042170882225037}, {\"reward\": 0.9697573781013489}, {\"reward\": 0.5696312785148621}, {\"reward\": 0.8657746315002441}, {\"reward\": 0.5458700060844421}, {\"reward\": 0.8363010287284851}, {\"reward\": 0.5351132154464722}, {\"reward\": 0.08076758682727814}, {\"reward\": 0.9285950064659119}, {\"reward\": 0.7054589986801147}, {\"reward\": 0.7439358830451965}, {\"reward\": 0.5445753335952759}, {\"reward\": 0.5551834106445312}, {\"reward\": 0.8025031089782715}, {\"reward\": 0.2500404715538025}, {\"reward\": 0.4929523169994354}, {\"reward\": 0.2534191310405731}, {\"reward\": 1.0390069484710693}, {\"reward\": 0.6831834316253662}, {\"reward\": 0.6869556307792664}, {\"reward\": 0.2817605435848236}, {\"reward\": 0.6413698792457581}, {\"reward\": 0.9784418940544128}, {\"reward\": -0.10980324447154999}, {\"reward\": 0.6093040108680725}, {\"reward\": 0.8909989595413208}, {\"reward\": 0.7423036694526672}, {\"reward\": 0.9136561751365662}, {\"reward\": 0.18219974637031555}, {\"reward\": 0.721316397190094}, {\"reward\": 0.34640365839004517}, {\"reward\": 0.7252675890922546}, {\"reward\": 0.30456075072288513}, {\"reward\": 0.036192141473293304}, {\"reward\": 0.9070278406143188}, {\"reward\": 0.8401719331741333}, {\"reward\": 0.9619526267051697}, {\"reward\": 0.9558541774749756}, {\"reward\": 0.5351555943489075}, {\"reward\": 0.7524368166923523}, {\"reward\": 1.1548391580581665}, {\"reward\": 1.1594641208648682}, {\"reward\": 0.8348330855369568}, {\"reward\": 0.8338356018066406}, {\"reward\": 0.00820031389594078}, {\"reward\": 0.9031581878662109}, {\"reward\": 0.5507419109344482}, {\"reward\": 1.0874260663986206}, {\"reward\": 0.5457856059074402}, {\"reward\": 0.974096953868866}, {\"reward\": 0.5133524537086487}, {\"reward\": 0.7929693460464478}, {\"reward\": 0.7455748319625854}, {\"reward\": 0.7959136366844177}, {\"reward\": 0.9271311163902283}, {\"reward\": 0.7293817400932312}, {\"reward\": 0.48770564794540405}, {\"reward\": 0.872734546661377}, {\"reward\": 0.6452435851097107}, {\"reward\": 0.8326128125190735}, {\"reward\": 0.5037161111831665}, {\"reward\": 0.31500306725502014}, {\"reward\": 0.279218465089798}, {\"reward\": 0.43921959400177}, {\"reward\": 1.0737675428390503}, {\"reward\": 0.5032007098197937}, {\"reward\": 0.6656485199928284}, {\"reward\": 0.38292884826660156}, {\"reward\": 0.6737605333328247}, {\"reward\": 0.4231223464012146}, {\"reward\": 0.6726577281951904}, {\"reward\": 1.0019854307174683}, {\"reward\": 0.3980712592601776}, {\"reward\": 0.8191760778427124}, {\"reward\": 0.5381521582603455}, {\"reward\": 0.017287906259298325}, {\"reward\": 0.5207902193069458}, {\"reward\": 0.8498796224594116}, {\"reward\": 0.7955881953239441}, {\"reward\": 0.645326554775238}, {\"reward\": 1.063637137413025}, {\"reward\": 0.8798330426216125}, {\"reward\": 0.4899439811706543}, {\"reward\": 0.5218079686164856}, {\"reward\": 1.130748987197876}, {\"reward\": 0.8719349503517151}, {\"reward\": 0.8208891749382019}, {\"reward\": 0.9669026136398315}, {\"reward\": 1.2104315757751465}, {\"reward\": 0.9969643950462341}, {\"reward\": 0.28028708696365356}, {\"reward\": 0.9576734900474548}, {\"reward\": 0.07083839923143387}, {\"reward\": -0.0318235382437706}, {\"reward\": 1.0590708255767822}, {\"reward\": 0.8681958317756653}, {\"reward\": 0.43324699997901917}, {\"reward\": 0.47233089804649353}, {\"reward\": 0.23065784573554993}, {\"reward\": 0.7788822054862976}, {\"reward\": 0.7690658569335938}, {\"reward\": 0.8198644518852234}, {\"reward\": 0.37364518642425537}, {\"reward\": 1.1294467449188232}, {\"reward\": 0.8103281259536743}, {\"reward\": 0.8654844164848328}, {\"reward\": 0.7675429582595825}, {\"reward\": 1.282814621925354}, {\"reward\": 0.6955093145370483}, {\"reward\": 0.5468578934669495}, {\"reward\": 0.4774988889694214}, {\"reward\": 0.8438447713851929}, {\"reward\": 1.2621020078659058}, {\"reward\": 0.2719680070877075}, {\"reward\": 0.2823343873023987}, {\"reward\": 0.9619772434234619}, {\"reward\": 0.5220873951911926}, {\"reward\": 0.699635922908783}, {\"reward\": 1.02866530418396}, {\"reward\": 0.678321123123169}, {\"reward\": 0.960387647151947}, {\"reward\": 0.6868608593940735}, {\"reward\": 0.3259906470775604}, {\"reward\": 0.9537989497184753}, {\"reward\": 0.03678737208247185}, {\"reward\": 0.7038145661354065}, {\"reward\": 0.7032041549682617}, {\"reward\": 1.193605661392212}, {\"reward\": 1.0206507444381714}, {\"reward\": 0.9000566005706787}, {\"reward\": 0.07655873894691467}, {\"reward\": 0.5744906663894653}, {\"reward\": 0.541045606136322}, {\"reward\": 0.8112964034080505}, {\"reward\": 0.20331676304340363}, {\"reward\": 0.9032032489776611}, {\"reward\": 0.7871862053871155}, {\"reward\": 0.5152737498283386}, {\"reward\": 0.8523575663566589}, {\"reward\": 0.9304145574569702}, {\"reward\": 0.8897441625595093}, {\"reward\": 0.566665530204773}, {\"reward\": 0.9282844662666321}, {\"reward\": 0.9263195991516113}, {\"reward\": 0.5601844787597656}, {\"reward\": 0.8205947875976562}, {\"reward\": 0.9712809920310974}, {\"reward\": 1.0142043828964233}, {\"reward\": 0.8055986762046814}, {\"reward\": 1.070958137512207}, {\"reward\": 0.9006569385528564}, {\"reward\": 0.834405779838562}, {\"reward\": 0.9115434885025024}, {\"reward\": 0.6129103899002075}, {\"reward\": 0.7823251485824585}, {\"reward\": 0.09737394750118256}, {\"reward\": 0.6667464375495911}, {\"reward\": 0.6554815173149109}, {\"reward\": 0.8913031220436096}, {\"reward\": 0.7592024803161621}, {\"reward\": 0.898034393787384}, {\"reward\": 0.8232992887496948}, {\"reward\": 0.9924447536468506}, {\"reward\": 0.797875702381134}, {\"reward\": 0.9031100273132324}, {\"reward\": 0.49968811869621277}, {\"reward\": 0.7185877561569214}, {\"reward\": 0.25166016817092896}, {\"reward\": 1.190908432006836}, {\"reward\": 0.510309636592865}, {\"reward\": 0.08215884864330292}, {\"reward\": 0.5006139874458313}, {\"reward\": 1.04836905002594}, {\"reward\": 0.6731218695640564}, {\"reward\": 0.5706737637519836}, {\"reward\": 0.7342638969421387}, {\"reward\": 0.43958330154418945}, {\"reward\": 0.7332132458686829}, {\"reward\": 0.6141947507858276}, {\"reward\": 0.645538866519928}, {\"reward\": 1.1624213457107544}, {\"reward\": 0.19840215146541595}, {\"reward\": 0.3545016050338745}, {\"reward\": 0.32030245661735535}, {\"reward\": 0.6399260759353638}, {\"reward\": 0.5383675694465637}, {\"reward\": 0.4108196794986725}, {\"reward\": 0.6867921352386475}, {\"reward\": 1.0433419942855835}, {\"reward\": 0.8603024482727051}, {\"reward\": 0.9188770651817322}, {\"reward\": 0.7654185891151428}, {\"reward\": 0.8056530356407166}, {\"reward\": 0.8442925810813904}, {\"reward\": 0.4495619237422943}, {\"reward\": 0.6099855899810791}, {\"reward\": 1.0456442832946777}, {\"reward\": 1.1685740947723389}, {\"reward\": 0.6961121559143066}, {\"reward\": 0.7085201144218445}, {\"reward\": 1.1063570976257324}, {\"reward\": 0.7100874781608582}, {\"reward\": 0.9800523519515991}, {\"reward\": 0.7735840678215027}, {\"reward\": 0.9264153838157654}, {\"reward\": 1.1705350875854492}, {\"reward\": -0.08450707793235779}, {\"reward\": 0.9307267069816589}, {\"reward\": 1.0316104888916016}, {\"reward\": 0.6059144139289856}, {\"reward\": 0.592880129814148}, {\"reward\": 0.9514927864074707}, {\"reward\": 0.8645694851875305}, {\"reward\": 0.277118057012558}, {\"reward\": 0.9142475128173828}, {\"reward\": -0.10665351152420044}, {\"reward\": 0.7819831967353821}, {\"reward\": 0.86623215675354}, {\"reward\": 0.7190398573875427}, {\"reward\": 0.8690745234489441}, {\"reward\": 0.4915027618408203}, {\"reward\": 0.8158785104751587}, {\"reward\": 0.19291597604751587}, {\"reward\": 0.8975000381469727}, {\"reward\": 0.9746758937835693}, {\"reward\": 0.04927391931414604}, {\"reward\": 0.7264029383659363}, {\"reward\": 0.7646912932395935}, {\"reward\": 0.36907958984375}, {\"reward\": 0.23021358251571655}, {\"reward\": 0.6205984354019165}, {\"reward\": 0.5750614404678345}, {\"reward\": 0.9346414804458618}, {\"reward\": 0.7541730403900146}, {\"reward\": 0.9979724287986755}, {\"reward\": 0.3427749276161194}, {\"reward\": 0.22764256596565247}, {\"reward\": 1.0299988985061646}, {\"reward\": 0.19671425223350525}, {\"reward\": 0.8321633338928223}, {\"reward\": 0.9745926856994629}, {\"reward\": 0.47700339555740356}, {\"reward\": 0.5082889199256897}, {\"reward\": 0.655128538608551}, {\"reward\": 0.7896328568458557}, {\"reward\": 0.43141308426856995}, {\"reward\": 0.4935343265533447}, {\"reward\": 0.023338641971349716}, {\"reward\": 0.9046846032142639}, {\"reward\": 0.9137444496154785}, {\"reward\": 0.6633472442626953}, {\"reward\": 1.0062018632888794}, {\"reward\": 0.9750932455062866}, {\"reward\": 0.6155254244804382}, {\"reward\": 0.5950482487678528}, {\"reward\": 0.22930128872394562}, {\"reward\": 0.6618379354476929}, {\"reward\": 0.8960256576538086}, {\"reward\": 1.0372623205184937}, {\"reward\": 0.7282395958900452}, {\"reward\": 0.12046414613723755}, {\"reward\": 0.2546527683734894}, {\"reward\": 0.786113977432251}, {\"reward\": 1.1500047445297241}, {\"reward\": 0.8247461318969727}, {\"reward\": 1.0902284383773804}, {\"reward\": 0.09222685545682907}, {\"reward\": 0.7429860830307007}, {\"reward\": 1.0138838291168213}, {\"reward\": 0.47829118371009827}, {\"reward\": 0.8751000761985779}, {\"reward\": 0.8430613279342651}, {\"reward\": 0.5700101852416992}, {\"reward\": 0.16186735033988953}, {\"reward\": -0.05746234580874443}, {\"reward\": 0.5591252446174622}, {\"reward\": 1.024091362953186}, {\"reward\": 0.19896656274795532}, {\"reward\": -0.012183972634375095}, {\"reward\": 0.7099202275276184}, {\"reward\": 0.2956467866897583}, {\"reward\": 0.1500331461429596}, {\"reward\": 0.22920463979244232}, {\"reward\": 0.6123286485671997}, {\"reward\": 0.38213303685188293}, {\"reward\": 0.028042953461408615}, {\"reward\": 1.0087645053863525}, {\"reward\": 0.8388662934303284}, {\"reward\": 0.6847264170646667}, {\"reward\": 0.7664045691490173}, {\"reward\": -0.00794379785656929}, {\"reward\": 0.7894331216812134}, {\"reward\": 0.6716510057449341}, {\"reward\": 0.09748105704784393}, {\"reward\": 0.6223863959312439}, {\"reward\": 0.7270883321762085}, {\"reward\": 0.559263288974762}, {\"reward\": 0.718720018863678}, {\"reward\": 1.0463899374008179}, {\"reward\": 0.9904232621192932}, {\"reward\": 0.24981500208377838}, {\"reward\": 0.9713922142982483}, {\"reward\": 0.791765570640564}, {\"reward\": 0.739392876625061}, {\"reward\": 0.8014533519744873}, {\"reward\": 0.8505420088768005}, {\"reward\": 0.9482046961784363}, {\"reward\": 0.4550243616104126}, {\"reward\": 0.40853410959243774}, {\"reward\": 1.0995498895645142}, {\"reward\": 1.0415308475494385}, {\"reward\": 0.8861256837844849}, {\"reward\": 0.4308118522167206}, {\"reward\": 0.6083791255950928}, {\"reward\": 0.5802363157272339}, {\"reward\": 0.5899118185043335}, {\"reward\": 0.5231316089630127}, {\"reward\": 0.11886874586343765}, {\"reward\": 0.4234127104282379}, {\"reward\": 0.6571082472801208}, {\"reward\": 0.870673418045044}, {\"reward\": 0.44687142968177795}, {\"reward\": 1.1235697269439697}, {\"reward\": 0.17662787437438965}, {\"reward\": 1.1319706439971924}, {\"reward\": 1.1821000576019287}, {\"reward\": 0.6915354132652283}, {\"reward\": 0.7857667803764343}, {\"reward\": 0.7087060809135437}, {\"reward\": 0.9440982341766357}, {\"reward\": 0.5554283261299133}, {\"reward\": 0.17012904584407806}, {\"reward\": 0.2566376328468323}, {\"reward\": 0.7543554306030273}, {\"reward\": 0.9082756042480469}, {\"reward\": 0.22740726172924042}, {\"reward\": 0.7197822332382202}, {\"reward\": 0.028435364365577698}, {\"reward\": 0.761613130569458}, {\"reward\": 0.5887980461120605}, {\"reward\": 0.9541966319084167}, {\"reward\": 0.4178921580314636}, {\"reward\": 0.4753126800060272}, {\"reward\": 1.0277544260025024}, {\"reward\": 0.9398978352546692}, {\"reward\": 0.9792780876159668}, {\"reward\": 0.2182132601737976}, {\"reward\": 0.40189024806022644}, {\"reward\": 0.8925433158874512}, {\"reward\": 0.3684937357902527}, {\"reward\": 0.7882410287857056}, {\"reward\": 0.3633543848991394}, {\"reward\": 0.8487321138381958}, {\"reward\": 0.6266693472862244}, {\"reward\": 0.7168370485305786}, {\"reward\": 0.10187055915594101}, {\"reward\": 0.8446696996688843}, {\"reward\": 0.29141518473625183}, {\"reward\": 0.9114193320274353}, {\"reward\": 0.5957898497581482}, {\"reward\": 0.9296924471855164}, {\"reward\": 1.0943336486816406}, {\"reward\": 0.5678231716156006}, {\"reward\": 0.8043556809425354}, {\"reward\": 0.824517011642456}, {\"reward\": 1.1440597772598267}, {\"reward\": 0.3059823215007782}, {\"reward\": 0.26292693614959717}, {\"reward\": 1.0649917125701904}, {\"reward\": 1.0693987607955933}, {\"reward\": 0.7326884269714355}, {\"reward\": 0.1130838468670845}, {\"reward\": 0.9345914721488953}, {\"reward\": 0.6306276917457581}, {\"reward\": 0.8145373463630676}, {\"reward\": 0.7189499735832214}, {\"reward\": 1.019203782081604}, {\"reward\": 0.45205092430114746}, {\"reward\": 0.14231593906879425}, {\"reward\": 0.08820284157991409}, {\"reward\": 0.7140918374061584}, {\"reward\": 0.8883341550827026}, {\"reward\": 0.9824140667915344}, {\"reward\": 0.49416589736938477}, {\"reward\": 0.5273510217666626}, {\"reward\": 0.9233805537223816}, {\"reward\": 0.7113399505615234}, {\"reward\": 0.8032423257827759}, {\"reward\": 0.8150665163993835}, {\"reward\": 1.1032826900482178}, {\"reward\": 0.7764707803726196}, {\"reward\": 0.35592398047447205}, {\"reward\": 0.9740256667137146}, {\"reward\": 0.6022830009460449}, {\"reward\": 1.0342856645584106}, {\"reward\": 0.685413658618927}, {\"reward\": 0.9484668374061584}, {\"reward\": 0.9837824702262878}, {\"reward\": 0.722365140914917}, {\"reward\": 0.7908312082290649}, {\"reward\": 0.7788395285606384}, {\"reward\": 1.016867995262146}, {\"reward\": 0.6720650792121887}, {\"reward\": 0.7223671078681946}, {\"reward\": 0.740338921546936}, {\"reward\": 0.6439340114593506}, {\"reward\": 0.3944440186023712}, {\"reward\": 0.585218608379364}, {\"reward\": 0.8579647541046143}, {\"reward\": 0.03871849551796913}, {\"reward\": 0.9512393474578857}, {\"reward\": 1.0716925859451294}, {\"reward\": 0.5660905241966248}, {\"reward\": 0.9885364770889282}, {\"reward\": 0.6372768878936768}, {\"reward\": 0.8013924956321716}, {\"reward\": 0.8100420832633972}, {\"reward\": 0.9369774460792542}, {\"reward\": 1.1650192737579346}, {\"reward\": 0.6482681632041931}, {\"reward\": 0.4903859794139862}, {\"reward\": 0.41949447989463806}, {\"reward\": 0.34112951159477234}, {\"reward\": 0.3237091600894928}, {\"reward\": 0.9415714144706726}, {\"reward\": 0.6316971182823181}, {\"reward\": 0.5003944635391235}, {\"reward\": 0.6836729049682617}, {\"reward\": 0.26054897904396057}, {\"reward\": 0.5465559363365173}, {\"reward\": 0.14737316966056824}, {\"reward\": 1.23345947265625}, {\"reward\": 0.333373099565506}, {\"reward\": 0.739210307598114}, {\"reward\": 0.74412602186203}, {\"reward\": 1.0632638931274414}, {\"reward\": 0.808745801448822}, {\"reward\": 0.6155532002449036}, {\"reward\": 1.0454058647155762}, {\"reward\": 0.9452553987503052}, {\"reward\": 0.8826207518577576}, {\"reward\": 0.7177280187606812}, {\"reward\": 0.991582989692688}, {\"reward\": 1.1537944078445435}, {\"reward\": 0.3767205476760864}, {\"reward\": 0.73387211561203}, {\"reward\": 0.9611015319824219}, {\"reward\": 0.8443814516067505}, {\"reward\": 0.3738468885421753}, {\"reward\": 0.884763777256012}, {\"reward\": 0.6456230282783508}, {\"reward\": 0.7747678756713867}, {\"reward\": 0.052338406443595886}, {\"reward\": 0.9331256151199341}, {\"reward\": 0.5957426428794861}, {\"reward\": 0.5841159820556641}, {\"reward\": 0.10287293046712875}, {\"reward\": 0.901016891002655}, {\"reward\": 0.504449188709259}, {\"reward\": 0.8655733466148376}, {\"reward\": -0.1640302538871765}, {\"reward\": 0.5799527168273926}, {\"reward\": 0.8234589695930481}, {\"reward\": 0.5272014141082764}, {\"reward\": 0.6932275295257568}, {\"reward\": 0.7483232617378235}, {\"reward\": 0.10347969084978104}, {\"reward\": 0.602048933506012}, {\"reward\": 0.002125059487298131}, {\"reward\": 0.3358748257160187}, {\"reward\": 0.8323023319244385}, {\"reward\": 1.284367322921753}, {\"reward\": 0.9178202748298645}, {\"reward\": 0.5875722765922546}, {\"reward\": 0.6010480523109436}, {\"reward\": 0.8173792958259583}, {\"reward\": 1.0382499694824219}, {\"reward\": 0.6667093634605408}, {\"reward\": 0.8379131555557251}, {\"reward\": 0.7989908456802368}, {\"reward\": 0.5708776712417603}, {\"reward\": 1.1067928075790405}, {\"reward\": 0.43024924397468567}, {\"reward\": 0.8129895329475403}, {\"reward\": 1.0187987089157104}, {\"reward\": 0.5625415444374084}, {\"reward\": 1.0128371715545654}, {\"reward\": 0.46568185091018677}, {\"reward\": 1.088982343673706}, {\"reward\": 0.7554406523704529}, {\"reward\": 0.876408576965332}, {\"reward\": 0.39087432622909546}, {\"reward\": 0.6794594526290894}, {\"reward\": 0.2607308626174927}, {\"reward\": 0.6473629474639893}, {\"reward\": 0.8936449289321899}, {\"reward\": 0.6963938474655151}, {\"reward\": 0.49945852160453796}, {\"reward\": 0.9020817279815674}, {\"reward\": 0.898059070110321}, {\"reward\": 1.099311351776123}, {\"reward\": 0.48665839433670044}, {\"reward\": 0.789706289768219}, {\"reward\": 0.3358173072338104}, {\"reward\": 1.031931757926941}, {\"reward\": 0.8850178122520447}, {\"reward\": 0.9619244933128357}, {\"reward\": 1.0360826253890991}, {\"reward\": 0.8889132142066956}, {\"reward\": 0.791892945766449}, {\"reward\": 0.6493790149688721}, {\"reward\": 0.8448702692985535}, {\"reward\": 0.901129961013794}, {\"reward\": 0.6561558842658997}, {\"reward\": 0.14049293100833893}, {\"reward\": 0.9588943719863892}, {\"reward\": 0.186873659491539}, {\"reward\": 0.9064727425575256}, {\"reward\": 0.9235644936561584}, {\"reward\": 1.0093859434127808}, {\"reward\": 0.8673493266105652}, {\"reward\": 0.9012678861618042}, {\"reward\": 0.7030389308929443}, {\"reward\": 0.9262872934341431}, {\"reward\": 1.0672367811203003}, {\"reward\": -0.08855132758617401}, {\"reward\": 1.0002566576004028}, {\"reward\": 0.8511428833007812}, {\"reward\": 0.9851923584938049}, {\"reward\": 0.37932711839675903}, {\"reward\": 0.8729197978973389}, {\"reward\": 0.19363725185394287}, {\"reward\": 0.45071542263031006}, {\"reward\": 0.8546844124794006}, {\"reward\": 0.7525816559791565}, {\"reward\": 0.948817253112793}, {\"reward\": 0.9619607329368591}, {\"reward\": 0.9307821989059448}, {\"reward\": 0.5278009176254272}, {\"reward\": 0.3536342680454254}, {\"reward\": 1.0899275541305542}, {\"reward\": 1.1071209907531738}, {\"reward\": 0.922299861907959}, {\"reward\": 0.8314294219017029}, {\"reward\": 0.8074601292610168}, {\"reward\": 0.778261125087738}, {\"reward\": 0.48675277829170227}, {\"reward\": 0.22329656779766083}, {\"reward\": 0.7877141237258911}, {\"reward\": 0.8267837762832642}, {\"reward\": 0.609512984752655}, {\"reward\": 1.0033708810806274}, {\"reward\": 0.7549319267272949}, {\"reward\": 0.7723371982574463}, {\"reward\": 0.8196998834609985}, {\"reward\": 1.1063016653060913}, {\"reward\": 0.10068952292203903}, {\"reward\": 0.7790964841842651}, {\"reward\": 0.07116101682186127}, {\"reward\": 1.0604817867279053}, {\"reward\": 0.467771053314209}, {\"reward\": 0.4570538103580475}, {\"reward\": -0.2315090000629425}, {\"reward\": 0.46075159311294556}, {\"reward\": -0.0013761918526142836}, {\"reward\": 0.8732379078865051}, {\"reward\": 0.48488396406173706}, {\"reward\": 0.8185173273086548}, {\"reward\": 0.5233919620513916}, {\"reward\": 0.9234878420829773}, {\"reward\": 0.5757893323898315}, {\"reward\": 1.2155351638793945}, {\"reward\": 0.765332043170929}, {\"reward\": 0.40964701771736145}, {\"reward\": 0.7765832543373108}, {\"reward\": 0.5830029845237732}, {\"reward\": 1.0447767972946167}, {\"reward\": 0.9727568030357361}, {\"reward\": 0.2984577715396881}, {\"reward\": 0.7084477543830872}, {\"reward\": 1.156126618385315}, {\"reward\": 0.9454768896102905}, {\"reward\": 0.28919458389282227}, {\"reward\": 0.733659029006958}, {\"reward\": 0.9442890882492065}, {\"reward\": 0.7963178753852844}, {\"reward\": 0.9408431053161621}, {\"reward\": -0.06037338823080063}, {\"reward\": 1.1165250539779663}, {\"reward\": 0.8570942282676697}, {\"reward\": 0.30801355838775635}, {\"reward\": 1.0883314609527588}, {\"reward\": -0.14373914897441864}, {\"reward\": 0.6626860499382019}, {\"reward\": 0.8217355012893677}, {\"reward\": 0.2002159208059311}, {\"reward\": 0.7763088941574097}, {\"reward\": 0.37710925936698914}, {\"reward\": 0.7333893179893494}, {\"reward\": 0.5230421423912048}, {\"reward\": 0.20688429474830627}, {\"reward\": 0.6927236914634705}, {\"reward\": 0.8628354072570801}, {\"reward\": 0.8956467509269714}, {\"reward\": 1.11562979221344}, {\"reward\": 0.797913670539856}, {\"reward\": 0.9836629033088684}, {\"reward\": 0.4691084027290344}, {\"reward\": 0.9198226928710938}, {\"reward\": 0.4469631314277649}, {\"reward\": 0.0033738077618181705}, {\"reward\": 1.1936023235321045}, {\"reward\": 0.61495441198349}, {\"reward\": 0.14579032361507416}, {\"reward\": 0.6702960133552551}, {\"reward\": 0.8990172147750854}, {\"reward\": 0.5486056804656982}, {\"reward\": 0.7114924788475037}, {\"reward\": 0.7048202753067017}, {\"reward\": 0.5778898596763611}, {\"reward\": 0.7351293563842773}, {\"reward\": 0.45019838213920593}, {\"reward\": 0.804222822189331}, {\"reward\": 0.20700816810131073}, {\"reward\": 1.0081958770751953}, {\"reward\": 0.2019612193107605}, {\"reward\": 0.9901596307754517}, {\"reward\": 0.794571042060852}, {\"reward\": 0.21111004054546356}, {\"reward\": 0.6849477887153625}, {\"reward\": 0.8198947906494141}, {\"reward\": 0.2989141345024109}, {\"reward\": 0.8313976526260376}, {\"reward\": 0.1491134762763977}, {\"reward\": 0.6168699264526367}, {\"reward\": 0.9625063538551331}, {\"reward\": 0.65891432762146}, {\"reward\": 0.9964859485626221}, {\"reward\": 0.7707784175872803}, {\"reward\": 0.38717442750930786}, {\"reward\": 0.6333169937133789}, {\"reward\": 0.7439946532249451}, {\"reward\": 0.9417924284934998}, {\"reward\": 0.4937266409397125}, {\"reward\": 0.599514365196228}, {\"reward\": 0.24718092381954193}, {\"reward\": 1.128502607345581}, {\"reward\": 0.48353251814842224}, {\"reward\": 0.6156249642372131}, {\"reward\": 0.2892605662345886}, {\"reward\": 0.8044067621231079}, {\"reward\": 0.52286696434021}, {\"reward\": 0.7317557334899902}, {\"reward\": 0.7151196002960205}, {\"reward\": 0.852307140827179}, {\"reward\": 0.14904803037643433}, {\"reward\": 0.8675447702407837}, {\"reward\": 1.0584567785263062}, {\"reward\": 0.8467249870300293}, {\"reward\": 0.9421935677528381}, {\"reward\": 0.8841121792793274}, {\"reward\": 0.19318163394927979}, {\"reward\": 0.7545598745346069}, {\"reward\": 0.023848041892051697}, {\"reward\": 0.26261529326438904}, {\"reward\": 0.8469269871711731}, {\"reward\": 0.772345781326294}, {\"reward\": 0.8378739953041077}, {\"reward\": 0.8412734866142273}, {\"reward\": 0.46420803666114807}, {\"reward\": 0.640755295753479}, {\"reward\": 1.0207315683364868}, {\"reward\": 0.659920334815979}, {\"reward\": 0.11193528026342392}, {\"reward\": 0.7581918239593506}, {\"reward\": 0.1512836217880249}, {\"reward\": 0.19730283319950104}, {\"reward\": 0.5723838210105896}, {\"reward\": 0.9244303703308105}, {\"reward\": 0.7551431059837341}, {\"reward\": 0.9415147304534912}, {\"reward\": 0.34791532158851624}, {\"reward\": 0.8912438750267029}, {\"reward\": 1.0208146572113037}, {\"reward\": 0.7047672867774963}, {\"reward\": 0.38928860425949097}, {\"reward\": 0.48137181997299194}, {\"reward\": 0.45394831895828247}, {\"reward\": 0.6332505345344543}, {\"reward\": 0.9981645345687866}, {\"reward\": -0.09738296270370483}, {\"reward\": 0.21373295783996582}, {\"reward\": 1.050324559211731}, {\"reward\": 0.7844945192337036}, {\"reward\": 0.6121224164962769}, {\"reward\": 0.44444409012794495}, {\"reward\": 0.7669978737831116}, {\"reward\": 0.7604275941848755}, {\"reward\": 0.6182951927185059}, {\"reward\": 0.8651513457298279}, {\"reward\": 1.059075117111206}, {\"reward\": 0.7875606417655945}, {\"reward\": 1.0957105159759521}, {\"reward\": 0.5507352352142334}, {\"reward\": 0.8083818554878235}, {\"reward\": 0.1414293348789215}, {\"reward\": 0.4318240284919739}, {\"reward\": 0.41216841340065}, {\"reward\": 0.9534410238265991}, {\"reward\": 0.9641942977905273}, {\"reward\": 0.7010677456855774}, {\"reward\": 0.7146621942520142}, {\"reward\": 0.9531184434890747}, {\"reward\": 0.9698894023895264}, {\"reward\": 0.27710792422294617}, {\"reward\": 0.7917100191116333}, {\"reward\": 0.9575908184051514}, {\"reward\": 1.0803226232528687}, {\"reward\": 1.1483654975891113}, {\"reward\": 0.44552019238471985}, {\"reward\": 1.0490494966506958}, {\"reward\": 0.7846961617469788}, {\"reward\": 0.9066468477249146}, {\"reward\": 0.5128140449523926}, {\"reward\": 1.1093883514404297}, {\"reward\": 0.9284894466400146}, {\"reward\": 1.0769996643066406}, {\"reward\": 0.8044577240943909}, {\"reward\": 0.638218104839325}, {\"reward\": 0.0904703438282013}, {\"reward\": 0.748958170413971}, {\"reward\": -0.12222672253847122}, {\"reward\": 0.1441105157136917}, {\"reward\": 0.9338043928146362}, {\"reward\": 0.8855184316635132}, {\"reward\": 0.6151564717292786}, {\"reward\": 0.9244258999824524}, {\"reward\": 0.7909837365150452}, {\"reward\": 0.7494591474533081}, {\"reward\": 0.5242054462432861}, {\"reward\": 1.0761356353759766}, {\"reward\": 0.9244111776351929}, {\"reward\": 0.900907576084137}, {\"reward\": 0.24429549276828766}, {\"reward\": 0.8785573244094849}, {\"reward\": 0.6021549105644226}, {\"reward\": 0.7663256525993347}, {\"reward\": 0.4434179663658142}, {\"reward\": 0.8865393996238708}, {\"reward\": 0.7006273865699768}, {\"reward\": 1.0334278345108032}, {\"reward\": 0.749310314655304}, {\"reward\": 1.0357383489608765}, {\"reward\": 1.0482738018035889}, {\"reward\": 0.8353369235992432}, {\"reward\": 0.5264891982078552}, {\"reward\": 0.6767373085021973}, {\"reward\": 0.35266926884651184}, {\"reward\": 0.5973215699195862}, {\"reward\": 0.6951372027397156}, {\"reward\": 0.8108289837837219}, {\"reward\": -0.07936704903841019}, {\"reward\": 1.034260869026184}, {\"reward\": 1.2853401899337769}, {\"reward\": 0.5768064260482788}, {\"reward\": 0.8140507936477661}, {\"reward\": 0.7829826474189758}, {\"reward\": 0.7663193345069885}, {\"reward\": 0.9675678610801697}, {\"reward\": 1.0267633199691772}, {\"reward\": 0.9030128717422485}, {\"reward\": 0.8070977926254272}, {\"reward\": 0.9700891375541687}, {\"reward\": 0.8869019150733948}, {\"reward\": 1.0678693056106567}, {\"reward\": 0.3907410502433777}, {\"reward\": 1.0366519689559937}, {\"reward\": 0.13978120684623718}, {\"reward\": 0.3513612747192383}, {\"reward\": 0.47216343879699707}, {\"reward\": 0.941885769367218}, {\"reward\": 0.5544285178184509}, {\"reward\": 0.9106214046478271}, {\"reward\": 0.8539068102836609}, {\"reward\": 0.839402437210083}, {\"reward\": 0.7971102595329285}, {\"reward\": 0.678451657295227}, {\"reward\": 1.082149863243103}, {\"reward\": 0.4126007854938507}, {\"reward\": 1.0745880603790283}, {\"reward\": -0.10156196355819702}, {\"reward\": 0.9818499088287354}, {\"reward\": 0.6851363182067871}, {\"reward\": 0.6789678931236267}, {\"reward\": 0.8598498702049255}, {\"reward\": 0.7915939688682556}, {\"reward\": -0.13459421694278717}, {\"reward\": 0.5188694596290588}, {\"reward\": 0.557732880115509}, {\"reward\": 0.8543832302093506}, {\"reward\": 0.13617342710494995}, {\"reward\": 0.0007332389941439033}, {\"reward\": 0.4937608540058136}, {\"reward\": 0.6763131618499756}, {\"reward\": 0.903249979019165}, {\"reward\": 0.521817147731781}, {\"reward\": 0.44134852290153503}, {\"reward\": 0.5481418967247009}, {\"reward\": 0.5282763242721558}, {\"reward\": 0.8214712738990784}, {\"reward\": 0.9579876065254211}, {\"reward\": 0.6836443543434143}, {\"reward\": -0.017184481024742126}, {\"reward\": 1.0312211513519287}, {\"reward\": 0.975627601146698}, {\"reward\": 0.05138130486011505}, {\"reward\": 0.6869174242019653}, {\"reward\": 0.5528828501701355}, {\"reward\": 0.7657890915870667}, {\"reward\": 0.749305009841919}, {\"reward\": 0.6522125601768494}, {\"reward\": 0.8478931784629822}, {\"reward\": 0.8138214349746704}, {\"reward\": 0.6112481355667114}, {\"reward\": 0.7402807474136353}, {\"reward\": 0.7200990319252014}, {\"reward\": 1.3233625888824463}, {\"reward\": 1.1040925979614258}, {\"reward\": 0.803914487361908}, {\"reward\": 0.8769049048423767}, {\"reward\": 0.14682424068450928}, {\"reward\": 1.153915286064148}, {\"reward\": 0.17659920454025269}, {\"reward\": 1.1453502178192139}, {\"reward\": 0.555218517780304}, {\"reward\": 0.9723746180534363}, {\"reward\": 0.3819001317024231}, {\"reward\": 0.8075323104858398}, {\"reward\": 1.1341667175292969}, {\"reward\": 1.0037435293197632}, {\"reward\": 0.4053545594215393}, {\"reward\": 0.6380966901779175}, {\"reward\": 0.6055679321289062}, {\"reward\": 0.603202760219574}, {\"reward\": 0.7494373917579651}, {\"reward\": 1.2526633739471436}, {\"reward\": -0.14861102402210236}, {\"reward\": 0.7169108986854553}, {\"reward\": 0.19935275614261627}, {\"reward\": 0.5003435015678406}, {\"reward\": 0.4068923592567444}, {\"reward\": 0.5761128067970276}, {\"reward\": 0.9302877187728882}, {\"reward\": 1.0131891965866089}, {\"reward\": 0.2993096113204956}, {\"reward\": 0.5431497693061829}, {\"reward\": 1.051565170288086}, {\"reward\": 0.567038893699646}, {\"reward\": 0.7975508570671082}, {\"reward\": 0.974867045879364}, {\"reward\": 1.05129075050354}, {\"reward\": 0.9009847044944763}, {\"reward\": 0.8976491093635559}, {\"reward\": 0.6454966068267822}, {\"reward\": 0.8315019011497498}, {\"reward\": -0.07500206679105759}, {\"reward\": 0.9231768250465393}, {\"reward\": 0.7435351610183716}, {\"reward\": 0.16227619349956512}, {\"reward\": 0.1686665564775467}, {\"reward\": 0.5343677401542664}, {\"reward\": 0.512360692024231}, {\"reward\": 0.10627106577157974}, {\"reward\": -0.03353678807616234}, {\"reward\": 0.2750359773635864}, {\"reward\": 0.7460284233093262}, {\"reward\": 0.8020448684692383}, {\"reward\": 0.6319608688354492}, {\"reward\": 0.9304999709129333}, {\"reward\": 0.6157079339027405}, {\"reward\": 0.915415346622467}, {\"reward\": 0.7607065439224243}, {\"reward\": 0.783727765083313}, {\"reward\": 0.5577962398529053}, {\"reward\": 0.12722675502300262}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot distribution plot using altaire\n",
    "alt.Chart(df_rewards).mark_bar().encode(\n",
    "    alt.X('reward', bin=alt.Bin(maxbins=100)),\n",
    "    y='count()',\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_train, df_generated], ignore_index=True)\n",
    "combined_df['data_type'] = ['train'] * len(df_train) + ['generated'] * len(df_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution plot using altaire\n",
    "alt.Chart(combined_df).mark_bar().encode(\n",
    "    alt.X('width', bin=alt.Bin(maxbins=100)),\n",
    "    y='count()',\n",
    "    color='data_type'\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generated['rewards']  = df_rewards['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_generated).mark_rect().encode(\n",
    "    alt.X('sdrop', bin=alt.Bin(maxbins=100)),\n",
    "    alt.Y('width', bin=alt.Bin(maxbins=100)),\n",
    "    alt.Color('rewards', scale=alt.Scale(scheme='redyellowblue'))\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the parameters of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# Define the objective function to optimize\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    input_noise = torch.randn(1, 100).to(device)\n",
    "    generator_model.eval()\n",
    "    generator_output = generator_model(input_noise)\n",
    "    generator_output = generator_output.squeeze(\n",
    "        0).detach().cpu().numpy().reshape(1, -1)\n",
    "    df_generated = process_for_supervised_model(generator_output)\n",
    "    reward = supervised_model.predict(df_generated)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the objective function for a fixed number of trials\n",
    "n_trials = 1000\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameter settings and reward found\n",
    "best_params = study.best_params\n",
    "best_reward = study.best_value\n",
    "print(f\"Best parameter settings: {best_params}\")\n",
    "print(f\"Best reward: {best_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
