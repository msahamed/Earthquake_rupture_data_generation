{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "from stable_baselines3 import PPO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "policy_kwargs = dict(activation_fn=th.nn.ReLU,\n",
    "                     net_arch=dict(pi=[16, 32, 64], vf=[16, 32, 64]))\n",
    "# Create the agent\n",
    "model = PPO(\"MlpPolicy\", \"CartPole-v1\", policy_kwargs=policy_kwargs, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=16, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Creating environment from the given name 'CartPole-v1'\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 21.6     |\n",
      "|    ep_rew_mean     | 21.6     |\n",
      "| time/              |          |\n",
      "|    fps             | 977      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 24.8         |\n",
      "|    ep_rew_mean          | 24.8         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 848          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071557118 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.69        |\n",
      "|    explained_variance   | -0.0369      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.2         |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00938     |\n",
      "|    value_loss           | 70           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 29.4         |\n",
      "|    ep_rew_mean          | 29.4         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 813          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060766367 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.676       |\n",
      "|    explained_variance   | -0.349       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 15.4         |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00915     |\n",
      "|    value_loss           | 57.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 40.5         |\n",
      "|    ep_rew_mean          | 40.5         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 798          |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 10           |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074773943 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.652       |\n",
      "|    explained_variance   | -0.138       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21.5         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0173      |\n",
      "|    value_loss           | 53.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 51.6         |\n",
      "|    ep_rew_mean          | 51.6         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 785          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059735375 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.636       |\n",
      "|    explained_variance   | 0.0617       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.8         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 64.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 66.8        |\n",
      "|    ep_rew_mean          | 66.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 787         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007889224 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.622      |\n",
      "|    explained_variance   | 0.141       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 69.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 82.3        |\n",
      "|    ep_rew_mean          | 82.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 794         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004290618 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.596      |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 81.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 97.9        |\n",
      "|    ep_rew_mean          | 97.9        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 793         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003872154 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.584      |\n",
      "|    explained_variance   | 0.576       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    value_loss           | 53.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 113          |\n",
      "|    ep_rew_mean          | 113          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 789          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026813783 |\n",
      "|    clip_fraction        | 0.016        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00689     |\n",
      "|    value_loss           | 49.3         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 127          |\n",
      "|    ep_rew_mean          | 127          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 787          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026987088 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.57        |\n",
      "|    explained_variance   | 0.675        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.3         |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    value_loss           | 46.8         |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Retrieve the environment\n",
    "env = model.get_env()\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=20_000)\n",
    "# Save the agent\n",
    "model.save(\"ppo_cartpole\")\n",
    "\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the policy_kwargs are automatically loaded\n",
    "model = PPO.load(\"ppo_cartpole\", env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=4, out_features=32, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (3): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (value_net): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
