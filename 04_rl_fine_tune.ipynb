{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import gym\n",
    "from stable_baselines3 import PPO, A2C, DQN, SAC, TD3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "random_state = 6\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (1600, 9) and test data shape (400, 9)\n"
     ]
    }
   ],
   "source": [
    "## look data with pandas\n",
    "train_file = \"data/rupturemodel_train.txt\"\n",
    "val_file = \"data/rupturemodel_validate.txt\"\n",
    "test_file = \"data/rupturemodel_test.txt\"\n",
    "\n",
    "df_train= pd.read_csv(train_file, sep=\" \", header = None)\n",
    "df_val= pd.read_csv(val_file, sep=\" \", header = None)\n",
    "df_test= pd.read_csv(test_file, sep=\" \", header = None)\n",
    "\n",
    "columns =  ['height', 'width', 'sxx', 'sxy', 'syy', 'sdrop', 'mud', 'dc', 'label']\n",
    "df_train.columns = columns\n",
    "df_val.columns = columns\n",
    "df_test.columns = columns\n",
    "\n",
    "frames = [df_train, df_val]\n",
    "df_train = pd.concat(frames)\n",
    "print('train data shape {} and test data shape {}'.format(np.shape(df_train), np.shape(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_new = df.copy()\n",
    "    # Create new features\n",
    "    df_new['height_width_ratio'] = df_new['height'] / df_new['width']\n",
    "    df_new['normal_stress_diff'] = df_new['sxx'] - df_new['syy']\n",
    "    df_new['friction_product'] = df_new['mud'] * (df_new['sdrop'])\n",
    "    df_new['stress_ratio'] = df_new['sxy'] / df_new['syy']\n",
    "    df_new['static_dynamic_friction_diff'] = (\n",
    "        df_new['mud'] + df_new['sdrop']) - df_new['mud']\n",
    "    df_new['stress_diff_dynamic_strength'] = df_new['sxy'] - \\\n",
    "        (df_new['syy'] * df_new['mud'])\n",
    "    df_new['normalized_dc'] = df_new['dc'] / df_new['width']\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data/rupturemodel_train.txt\"\n",
    "columns = ['height', 'width', 'sxx', 'sxy',\n",
    "           'syy', 'sdrop', 'mud', 'dc', 'label']\n",
    "df_train = pd.read_csv(train_file, sep=\" \", header=None)\n",
    "df_train.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your reinforcement learning environment\n",
    "from typing import List\n",
    "\n",
    "class GeneratorEnv(gym.Env):\n",
    "    def __init__(self, supervised_model):\n",
    "        super(GeneratorEnv, self).__init__()\n",
    "        self.supervised_model = supervised_model\n",
    "        self.generator_input_size = 100\n",
    "        self.scaler = joblib.load('./models/scaler.pkl')\n",
    "        self.state = torch.randn(100).to(device)\n",
    "        self.action_space = gym.spaces.Box( low = 0, high = 1, shape = (8,), dtype = np.float32)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(100,), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.state = torch.randn(1, self.generator_input_size).to(device)\n",
    "        self.generator_model.eval()\n",
    "        processed_data = self.process_for_supervised_model(np.array(action))\n",
    "        reward = self.supervised_model.predict(processed_data)\n",
    "        done = False\n",
    "        info = {}\n",
    "        return self.state.cpu().numpy(), reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = torch.randn(100).to(device)\n",
    "        return self.state.cpu().numpy()\n",
    "\n",
    "    def process_for_supervised_model(self, generated_data: np.array) -> np.array:\n",
    "        # Process the generated data to make it compatible with the supervised model\n",
    "        columns = ['height', 'width', 'sxx',\n",
    "                   'sxy', 'syy', 'sdrop', 'mud', 'dc']\n",
    "        de_normalized = self.scaler.inverse_transform(\n",
    "            generated_data.reshape(1, -1))  # Reshape to a 2D array\n",
    "        df = pd.DataFrame(de_normalized, columns=columns)\n",
    "        df = create_new_features(df)\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the custom environment\n",
    "supervised_model = lgb.Booster(model_file='./models/best_supervised_model.txt')\n",
    "env = DummyVecEnv([lambda: GeneratorEnv(supervised_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to ./logs/rl_logs/PPO_21\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 322  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 6    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 13         |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02164761 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -11.3      |\n",
      "|    explained_variance   | -0.312     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.2       |\n",
      "|    n_updates            | 10         |\n",
      "|    policy_gradient_loss | -0.0564    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 39.4       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018729962 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | -1.09       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.057      |\n",
      "|    std                  | 0.994       |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 303         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026768614 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.3       |\n",
      "|    explained_variance   | -1.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0576     |\n",
      "|    std                  | 0.986       |\n",
      "|    value_loss           | 9.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027937233 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -1.59       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.607       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.06       |\n",
      "|    std                  | 0.98        |\n",
      "|    value_loss           | 6.9         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030462693 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.2       |\n",
      "|    explained_variance   | -0.746      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.502       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0643     |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 5.49        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 46          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038300905 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | -0.323      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.393       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0705     |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 3.89        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033551313 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11.1       |\n",
      "|    explained_variance   | -0.136      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.347       |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.064      |\n",
      "|    std                  | 0.965       |\n",
      "|    value_loss           | 4.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035711415 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -11         |\n",
      "|    explained_variance   | -0.0612     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.436       |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0643     |\n",
      "|    std                  | 0.955       |\n",
      "|    value_loss           | 3.59        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 306        |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 66         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03102212 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.9      |\n",
      "|    explained_variance   | -0.0485    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.557      |\n",
      "|    n_updates            | 90         |\n",
      "|    policy_gradient_loss | -0.0627    |\n",
      "|    std                  | 0.946      |\n",
      "|    value_loss           | 3.65       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031563573 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.8       |\n",
      "|    explained_variance   | -0.0864     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.31        |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0646     |\n",
      "|    std                  | 0.936       |\n",
      "|    value_loss           | 3.1         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034581006 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.8       |\n",
      "|    explained_variance   | -0.0239     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.07       |\n",
      "|    std                  | 0.924       |\n",
      "|    value_loss           | 2.39        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 306         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036694154 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.7       |\n",
      "|    explained_variance   | -0.0519     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.325       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0704     |\n",
      "|    std                  | 0.918       |\n",
      "|    value_loss           | 2.43        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 304        |\n",
      "|    iterations           | 14         |\n",
      "|    time_elapsed         | 94         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03490097 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.6      |\n",
      "|    explained_variance   | -0.0311    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.413      |\n",
      "|    n_updates            | 130        |\n",
      "|    policy_gradient_loss | -0.0729    |\n",
      "|    std                  | 0.911      |\n",
      "|    value_loss           | 2.22       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 100         |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034485176 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | -0.0427     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.372       |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0714     |\n",
      "|    std                  | 0.902       |\n",
      "|    value_loss           | 2           |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031679112 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.5       |\n",
      "|    explained_variance   | -0.00299    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.379       |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.072      |\n",
      "|    std                  | 0.894       |\n",
      "|    value_loss           | 2.22        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 303        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 114        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03477262 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -10.4      |\n",
      "|    explained_variance   | -0.0111    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.277      |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.0706    |\n",
      "|    std                  | 0.882      |\n",
      "|    value_loss           | 2.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 302         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 121         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032772787 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.3       |\n",
      "|    explained_variance   | -0.0099     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.427       |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0736     |\n",
      "|    std                  | 0.874       |\n",
      "|    value_loss           | 1.96        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 128         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032820813 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.2       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.27        |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.072      |\n",
      "|    std                  | 0.863       |\n",
      "|    value_loss           | 1.76        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036384195 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -10.1       |\n",
      "|    explained_variance   | -0.0491     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.238       |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0796     |\n",
      "|    std                  | 0.85        |\n",
      "|    value_loss           | 1.38        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 142         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035519954 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.95       |\n",
      "|    explained_variance   | -0.0238     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.163       |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0782     |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 300         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 150         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036567945 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.84       |\n",
      "|    explained_variance   | -0.00428    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.306       |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0819     |\n",
      "|    std                  | 0.829       |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 157        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03619903 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.74      |\n",
      "|    explained_variance   | -0.00788   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.177      |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0802    |\n",
      "|    std                  | 0.82       |\n",
      "|    value_loss           | 1.01       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 299        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 164        |\n",
      "|    total_timesteps      | 49152      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03539194 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.64      |\n",
      "|    explained_variance   | -0.0449    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0941     |\n",
      "|    n_updates            | 230        |\n",
      "|    policy_gradient_loss | -0.084     |\n",
      "|    std                  | 0.81       |\n",
      "|    value_loss           | 0.883      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 297       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 171       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0387635 |\n",
      "|    clip_fraction        | 0.33      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -9.55     |\n",
      "|    explained_variance   | -0.0103   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.148     |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -0.0853   |\n",
      "|    std                  | 0.801     |\n",
      "|    value_loss           | 0.804     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 179        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03711641 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.44      |\n",
      "|    explained_variance   | -0.0125    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0645     |\n",
      "|    n_updates            | 250        |\n",
      "|    policy_gradient_loss | -0.0863    |\n",
      "|    std                  | 0.791      |\n",
      "|    value_loss           | 0.866      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 186        |\n",
      "|    total_timesteps      | 55296      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03914746 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.34      |\n",
      "|    explained_variance   | 0.00186    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0737     |\n",
      "|    n_updates            | 260        |\n",
      "|    policy_gradient_loss | -0.0866    |\n",
      "|    std                  | 0.782      |\n",
      "|    value_loss           | 0.743      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039035354 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.25       |\n",
      "|    explained_variance   | -0.133      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0153      |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.0892     |\n",
      "|    std                  | 0.774       |\n",
      "|    value_loss           | 0.665       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 201         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038896725 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.17       |\n",
      "|    explained_variance   | -0.0118     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0527      |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.0903     |\n",
      "|    std                  | 0.766       |\n",
      "|    value_loss           | 0.51        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 61440       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042054694 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.08       |\n",
      "|    explained_variance   | -0.00671    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0671      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.0926     |\n",
      "|    std                  | 0.758       |\n",
      "|    value_loss           | 0.538       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 295         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 214         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039844837 |\n",
      "|    clip_fraction        | 0.387       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9          |\n",
      "|    explained_variance   | -0.0167     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0194      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.092      |\n",
      "|    std                  | 0.751       |\n",
      "|    value_loss           | 0.439       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 32         |\n",
      "|    time_elapsed         | 221        |\n",
      "|    total_timesteps      | 65536      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04452646 |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.9       |\n",
      "|    explained_variance   | -0.0686    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00515    |\n",
      "|    n_updates            | 310        |\n",
      "|    policy_gradient_loss | -0.0965    |\n",
      "|    std                  | 0.741      |\n",
      "|    value_loss           | 0.369      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 295        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 228        |\n",
      "|    total_timesteps      | 67584      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04608827 |\n",
      "|    clip_fraction        | 0.412      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.8       |\n",
      "|    explained_variance   | -0.0596    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0271    |\n",
      "|    n_updates            | 320        |\n",
      "|    policy_gradient_loss | -0.0937    |\n",
      "|    std                  | 0.732      |\n",
      "|    value_loss           | 0.346      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 296        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 235        |\n",
      "|    total_timesteps      | 69632      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04451666 |\n",
      "|    clip_fraction        | 0.402      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.7       |\n",
      "|    explained_variance   | -0.00845   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0373    |\n",
      "|    n_updates            | 330        |\n",
      "|    policy_gradient_loss | -0.097     |\n",
      "|    std                  | 0.725      |\n",
      "|    value_loss           | 0.327      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 71680       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043785118 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.65       |\n",
      "|    explained_variance   | -0.0134     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0453     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0956     |\n",
      "|    std                  | 0.723       |\n",
      "|    value_loss           | 0.269       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 248         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044314742 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.59       |\n",
      "|    explained_variance   | -0.00139    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0523     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0981     |\n",
      "|    std                  | 0.716       |\n",
      "|    value_loss           | 0.278       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 255         |\n",
      "|    total_timesteps      | 75776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046812616 |\n",
      "|    clip_fraction        | 0.417       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.49       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0526     |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0997     |\n",
      "|    std                  | 0.706       |\n",
      "|    value_loss           | 0.246       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045491092 |\n",
      "|    clip_fraction        | 0.409       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.39       |\n",
      "|    explained_variance   | -0.11       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0538     |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.0962     |\n",
      "|    std                  | 0.699       |\n",
      "|    value_loss           | 0.229       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046512846 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.29       |\n",
      "|    explained_variance   | -0.086      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0563     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0987     |\n",
      "|    std                  | 0.69        |\n",
      "|    value_loss           | 0.206       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 297        |\n",
      "|    iterations           | 40         |\n",
      "|    time_elapsed         | 275        |\n",
      "|    total_timesteps      | 81920      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04198524 |\n",
      "|    clip_fraction        | 0.401      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.2       |\n",
      "|    explained_variance   | -0.0168    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0316    |\n",
      "|    n_updates            | 390        |\n",
      "|    policy_gradient_loss | -0.0987    |\n",
      "|    std                  | 0.682      |\n",
      "|    value_loss           | 0.23       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 282         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047659792 |\n",
      "|    clip_fraction        | 0.422       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -8.12       |\n",
      "|    explained_variance   | 0.000406    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0106     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.101      |\n",
      "|    std                  | 0.675       |\n",
      "|    value_loss           | 0.205       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 297        |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 289        |\n",
      "|    total_timesteps      | 86016      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04568439 |\n",
      "|    clip_fraction        | 0.417      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -8.03      |\n",
      "|    explained_variance   | -0.142     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0664    |\n",
      "|    n_updates            | 410        |\n",
      "|    policy_gradient_loss | -0.0968    |\n",
      "|    std                  | 0.668      |\n",
      "|    value_loss           | 0.178      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046988863 |\n",
      "|    clip_fraction        | 0.413       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.93       |\n",
      "|    explained_variance   | -0.00363    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0496     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.1        |\n",
      "|    std                  | 0.66        |\n",
      "|    value_loss           | 0.186       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 297        |\n",
      "|    iterations           | 44         |\n",
      "|    time_elapsed         | 302        |\n",
      "|    total_timesteps      | 90112      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04908379 |\n",
      "|    clip_fraction        | 0.442      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.82      |\n",
      "|    explained_variance   | -0.0686    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0704    |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.101     |\n",
      "|    std                  | 0.651      |\n",
      "|    value_loss           | 0.175      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051534265 |\n",
      "|    clip_fraction        | 0.432       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.72       |\n",
      "|    explained_variance   | -0.00643    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0539     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.102      |\n",
      "|    std                  | 0.643       |\n",
      "|    value_loss           | 0.166       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 297        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 316        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04649099 |\n",
      "|    clip_fraction        | 0.428      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -7.61      |\n",
      "|    explained_variance   | -0.0201    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.034     |\n",
      "|    n_updates            | 450        |\n",
      "|    policy_gradient_loss | -0.0976    |\n",
      "|    std                  | 0.635      |\n",
      "|    value_loss           | 0.162      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 47          |\n",
      "|    time_elapsed         | 323         |\n",
      "|    total_timesteps      | 96256       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050634734 |\n",
      "|    clip_fraction        | 0.438       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.51       |\n",
      "|    explained_variance   | -0.0411     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0479     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0992     |\n",
      "|    std                  | 0.626       |\n",
      "|    value_loss           | 0.155       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 330         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051573385 |\n",
      "|    clip_fraction        | 0.454       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.39       |\n",
      "|    explained_variance   | -0.00907    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0893     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.103      |\n",
      "|    std                  | 0.617       |\n",
      "|    value_loss           | 0.14        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 297         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 337         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053891495 |\n",
      "|    clip_fraction        | 0.471       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -7.29       |\n",
      "|    explained_variance   | -0.00734    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0714     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.104      |\n",
      "|    std                  | 0.611       |\n",
      "|    value_loss           | 0.114       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f865c14b4c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the generator using PPO\n",
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=\"./logs/rl_logs/\")\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rl_model_ppo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/rl_model_ppo_env.joblib']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save the model with environment\n",
    "model.save(f'./models/{model_name}')\n",
    "joblib.dump(env, f'./models/{model_name}_env.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model\n",
    "loaded_model = PPO.load(f'./models/{model_name}')\n",
    "loaded_env = joblib.load(f'./models/{model_name}_env.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_array = []\n",
    "generated_data = []\n",
    "obs = loaded_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = loaded_model.predict(obs)\n",
    "    obs, rewards, dones, info = loaded_env.step(action)\n",
    "    generated_data.append(list(action[0]))\n",
    "    rewards_array.append(rewards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the generated data to make it compatible with the supervised model\n",
    "scaler = joblib.load('./models/scaler.pkl')\n",
    "def process_for_supervised_model(generated_data):\n",
    "    # Process the generated data to make it compatible with the supervised model\n",
    "    columns = ['height', 'width', 'sxx',\n",
    "               'sxy', 'syy', 'sdrop', 'mud', 'dc']\n",
    "    de_normalized = scaler.inverse_transform(generated_data)  # Reshape to a 2D array\n",
    "    df = pd.DataFrame(de_normalized, columns=columns)\n",
    "    df = create_new_features(df)\n",
    "    return df\n",
    "\n",
    "data = np.array(generated_data)\n",
    "df_generated = process_for_supervised_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>sxx</th>\n",
       "      <th>sxy</th>\n",
       "      <th>syy</th>\n",
       "      <th>sdrop</th>\n",
       "      <th>mud</th>\n",
       "      <th>dc</th>\n",
       "      <th>height_width_ratio</th>\n",
       "      <th>normal_stress_diff</th>\n",
       "      <th>friction_product</th>\n",
       "      <th>stress_ratio</th>\n",
       "      <th>static_dynamic_friction_diff</th>\n",
       "      <th>stress_diff_dynamic_strength</th>\n",
       "      <th>normalized_dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.074235</td>\n",
       "      <td>1.079330</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.351016</td>\n",
       "      <td>0.233045</td>\n",
       "      <td>0.068778</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.070407</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>153.761627</td>\n",
       "      <td>0.215916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.411556</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.040125</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>129.614456</td>\n",
       "      <td>0.411468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.277380</td>\n",
       "      <td>0.580134</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.055637</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>141.983856</td>\n",
       "      <td>0.580010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-43.043720</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.307973</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-155.599869</td>\n",
       "      <td>0.061773</td>\n",
       "      <td>-2.267885</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>110.874527</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-113.520729</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.406956</td>\n",
       "      <td>0.496606</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>46.424492</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>162.708862</td>\n",
       "      <td>0.496500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-122.617569</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>37.327652</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-29.470890</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>130.474335</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-114.239517</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-84.404068</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.854505</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>163.082825</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-78.017754</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>81.927467</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-154.805099</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>5.140121</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-7.933036</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>152.012192</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.519695</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.104240</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>180.741013</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.682647</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.493545</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.098995</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>176.558411</td>\n",
       "      <td>0.346687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.333967</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.066987</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>151.034607</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.031695</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-19.480804</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.031688</td>\n",
       "      <td>140.464417</td>\n",
       "      <td>0.144068</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.251408</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.828630</td>\n",
       "      <td>-188.629150</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.507043</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-28.683929</td>\n",
       "      <td>0.101702</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>178.717361</td>\n",
       "      <td>0.319010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-45.470112</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.498344</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>114.475113</td>\n",
       "      <td>0.099957</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>177.325989</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-78.973457</td>\n",
       "      <td>97.61821</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>80.971764</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       height     width         sxx       sxy         syy     sdrop       mud  \\\n",
       "64   0.074235  1.079330 -198.643585  97.61821 -159.945221  0.200579  0.351016   \n",
       "131  0.000003  1.000214 -198.643585  97.61821 -159.945221  0.200579  0.200045   \n",
       "958  0.000003  1.000214 -198.643585  97.61821 -159.945221  0.200579  0.277380   \n",
       "804  0.000003  1.000214 -198.643585  97.61821  -43.043720  0.200579  0.307973   \n",
       "699  0.000003  1.000214 -113.520729  97.61821 -159.945221  0.200579  0.406956   \n",
       "915  0.000003  1.000214 -122.617569  97.61821 -159.945221  0.200579  0.573047   \n",
       "654  0.000003  1.000214  -29.470890  97.61821 -159.945221  0.200579  0.573047   \n",
       "68   0.000003  1.000214 -198.643585  97.61821 -114.239517  0.200579  0.573047   \n",
       "106  0.000003  1.000214  -78.017754  97.61821 -159.945221  0.200579  0.573047   \n",
       "66   0.000003  1.000214 -154.805099  97.61821 -159.945221  0.200579  0.573047   \n",
       "25   0.000003  1.000214   -7.933036  97.61821 -159.945221  0.200579  0.573047   \n",
       "885  0.000003  1.000214 -198.643585  97.61821 -159.945221  0.200579  0.519695   \n",
       "817  0.000003  1.682647 -198.643585  97.61821 -159.945221  0.200579  0.493545   \n",
       "307  0.000003  1.000214 -198.643585  97.61821 -159.945221  0.200579  0.333967   \n",
       "547  0.000003  1.000214 -198.643585  97.61821 -159.945221  0.200579  0.573047   \n",
       "35   0.031695  1.000214  -19.480804  97.61821 -159.945221  0.251408  0.573047   \n",
       "875  0.000003  1.828630 -188.629150  97.61821 -159.945221  0.200579  0.507043   \n",
       "717  0.000003  1.000214  -45.470112  97.61821 -159.945221  0.200579  0.498344   \n",
       "423  0.000003  1.000214 -198.643585  97.61821 -159.945221  0.200579  0.573047   \n",
       "411  0.000003  1.000214  -78.973457  97.61821 -159.945221  0.200579  0.573047   \n",
       "\n",
       "           dc  height_width_ratio  normal_stress_diff  friction_product  \\\n",
       "64   0.233045            0.068778          -38.698364          0.070407   \n",
       "131  0.411556            0.000003          -38.698364          0.040125   \n",
       "958  0.580134            0.000003          -38.698364          0.055637   \n",
       "804  0.583352            0.000003         -155.599869          0.061773   \n",
       "699  0.496606            0.000003           46.424492          0.081627   \n",
       "915  0.583352            0.000003           37.327652          0.114941   \n",
       "654  0.583352            0.000003          130.474335          0.114941   \n",
       "68   0.583352            0.000003          -84.404068          0.114941   \n",
       "106  0.583352            0.000003           81.927467          0.114941   \n",
       "66   0.583352            0.000003            5.140121          0.114941   \n",
       "25   0.583352            0.000003          152.012192          0.114941   \n",
       "885  0.583352            0.000003          -38.698364          0.104240   \n",
       "817  0.583352            0.000002          -38.698364          0.098995   \n",
       "307  0.583352            0.000003          -38.698364          0.066987   \n",
       "547  0.583352            0.000003          -38.698364          0.114941   \n",
       "35   0.583352            0.031688          140.464417          0.144068   \n",
       "875  0.583352            0.000002          -28.683929          0.101702   \n",
       "717  0.583352            0.000003          114.475113          0.099957   \n",
       "423  0.583352            0.000003          -38.698364          0.114941   \n",
       "411  0.583352            0.000003           80.971764          0.114941   \n",
       "\n",
       "     stress_ratio  static_dynamic_friction_diff  stress_diff_dynamic_strength  \\\n",
       "64      -0.610323                      0.200579                    153.761627   \n",
       "131     -0.610323                      0.200579                    129.614456   \n",
       "958     -0.610323                      0.200579                    141.983856   \n",
       "804     -2.267885                      0.200579                    110.874527   \n",
       "699     -0.610323                      0.200579                    162.708862   \n",
       "915     -0.610323                      0.200579                    189.274338   \n",
       "654     -0.610323                      0.200579                    189.274338   \n",
       "68      -0.854505                      0.200579                    163.082825   \n",
       "106     -0.610323                      0.200579                    189.274338   \n",
       "66      -0.610323                      0.200579                    189.274338   \n",
       "25      -0.610323                      0.200579                    189.274338   \n",
       "885     -0.610323                      0.200579                    180.741013   \n",
       "817     -0.610323                      0.200579                    176.558411   \n",
       "307     -0.610323                      0.200579                    151.034607   \n",
       "547     -0.610323                      0.200579                    189.274338   \n",
       "35      -0.610323                      0.251408                    189.274338   \n",
       "875     -0.610323                      0.200579                    178.717361   \n",
       "717     -0.610323                      0.200579                    177.325989   \n",
       "423     -0.610323                      0.200579                    189.274338   \n",
       "411     -0.610323                      0.200579                    189.274338   \n",
       "\n",
       "     normalized_dc  \n",
       "64        0.215916  \n",
       "131       0.411468  \n",
       "958       0.580010  \n",
       "804       0.583227  \n",
       "699       0.496500  \n",
       "915       0.583227  \n",
       "654       0.583227  \n",
       "68        0.583227  \n",
       "106       0.583227  \n",
       "66        0.583227  \n",
       "25        0.583227  \n",
       "885       0.583227  \n",
       "817       0.346687  \n",
       "307       0.583227  \n",
       "547       0.583227  \n",
       "35        0.583227  \n",
       "875       0.319010  \n",
       "717       0.583227  \n",
       "423       0.583227  \n",
       "411       0.583227  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>sxx</th>\n",
       "      <th>sxy</th>\n",
       "      <th>syy</th>\n",
       "      <th>sdrop</th>\n",
       "      <th>mud</th>\n",
       "      <th>dc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.071747</td>\n",
       "      <td>1.492561</td>\n",
       "      <td>-85.727744</td>\n",
       "      <td>35.405536</td>\n",
       "      <td>-85.295950</td>\n",
       "      <td>0.390677</td>\n",
       "      <td>0.306744</td>\n",
       "      <td>0.401653</td>\n",
       "      <td>0.356000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.046195</td>\n",
       "      <td>0.289699</td>\n",
       "      <td>45.301701</td>\n",
       "      <td>20.402395</td>\n",
       "      <td>42.617577</td>\n",
       "      <td>0.112238</td>\n",
       "      <td>0.088545</td>\n",
       "      <td>0.051051</td>\n",
       "      <td>0.479055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-196.579802</td>\n",
       "      <td>2.491208</td>\n",
       "      <td>-159.945235</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.254480</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.030697</td>\n",
       "      <td>1.246860</td>\n",
       "      <td>-120.756137</td>\n",
       "      <td>19.565099</td>\n",
       "      <td>-121.961244</td>\n",
       "      <td>0.292298</td>\n",
       "      <td>0.233558</td>\n",
       "      <td>0.369119</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.068957</td>\n",
       "      <td>1.480246</td>\n",
       "      <td>-83.074266</td>\n",
       "      <td>32.316379</td>\n",
       "      <td>-86.022800</td>\n",
       "      <td>0.387075</td>\n",
       "      <td>0.285329</td>\n",
       "      <td>0.400085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.105718</td>\n",
       "      <td>1.739429</td>\n",
       "      <td>-48.382402</td>\n",
       "      <td>49.338103</td>\n",
       "      <td>-48.805945</td>\n",
       "      <td>0.482003</td>\n",
       "      <td>0.357936</td>\n",
       "      <td>0.434763</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.195712</td>\n",
       "      <td>2.085240</td>\n",
       "      <td>-7.933036</td>\n",
       "      <td>97.528776</td>\n",
       "      <td>-10.044879</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height        width          sxx          sxy          syy  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.071747     1.492561   -85.727744    35.405536   -85.295950   \n",
       "std       0.046195     0.289699    45.301701    20.402395    42.617577   \n",
       "min       0.000070     1.000214  -196.579802     2.491208  -159.945235   \n",
       "25%       0.030697     1.246860  -120.756137    19.565099  -121.961244   \n",
       "50%       0.068957     1.480246   -83.074266    32.316379   -86.022800   \n",
       "75%       0.105718     1.739429   -48.382402    49.338103   -48.805945   \n",
       "max       0.195712     2.085240    -7.933036    97.528776   -10.044879   \n",
       "\n",
       "             sdrop          mud           dc        label  \n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  \n",
       "mean      0.390677     0.306744     0.401653     0.356000  \n",
       "std       0.112238     0.088545     0.051051     0.479055  \n",
       "min       0.200579     0.200045     0.254480     0.000000  \n",
       "25%       0.292298     0.233558     0.369119     0.000000  \n",
       "50%       0.387075     0.285329     0.400085     0.000000  \n",
       "75%       0.482003     0.357936     0.434763     1.000000  \n",
       "max       0.599913     0.573047     0.583352     1.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>sxx</th>\n",
       "      <th>sxy</th>\n",
       "      <th>syy</th>\n",
       "      <th>sdrop</th>\n",
       "      <th>mud</th>\n",
       "      <th>dc</th>\n",
       "      <th>height_width_ratio</th>\n",
       "      <th>normal_stress_diff</th>\n",
       "      <th>friction_product</th>\n",
       "      <th>stress_ratio</th>\n",
       "      <th>static_dynamic_friction_diff</th>\n",
       "      <th>stress_diff_dynamic_strength</th>\n",
       "      <th>normalized_dc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.009920</td>\n",
       "      <td>1.145984</td>\n",
       "      <td>-152.410980</td>\n",
       "      <td>95.806030</td>\n",
       "      <td>-147.582855</td>\n",
       "      <td>0.213223</td>\n",
       "      <td>0.469055</td>\n",
       "      <td>0.509479</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>-4.828269</td>\n",
       "      <td>0.099655</td>\n",
       "      <td>-0.788919</td>\n",
       "      <td>0.213223</td>\n",
       "      <td>165.131363</td>\n",
       "      <td>0.466428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>65.652687</td>\n",
       "      <td>8.517452</td>\n",
       "      <td>30.211641</td>\n",
       "      <td>0.047509</td>\n",
       "      <td>0.136160</td>\n",
       "      <td>0.120401</td>\n",
       "      <td>0.028974</td>\n",
       "      <td>72.507317</td>\n",
       "      <td>0.034780</td>\n",
       "      <td>0.945068</td>\n",
       "      <td>0.047509</td>\n",
       "      <td>26.704126</td>\n",
       "      <td>0.139873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>6.414491</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.200045</td>\n",
       "      <td>0.233045</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-188.631592</td>\n",
       "      <td>0.040125</td>\n",
       "      <td>-9.750129</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>38.410732</td>\n",
       "      <td>0.109466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.618210</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.374204</td>\n",
       "      <td>0.464942</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.078491</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>145.352219</td>\n",
       "      <td>0.350090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>-198.643585</td>\n",
       "      <td>97.618210</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.568429</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-38.698364</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>174.424789</td>\n",
       "      <td>0.552838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.115994</td>\n",
       "      <td>-112.022064</td>\n",
       "      <td>97.618210</td>\n",
       "      <td>-159.945221</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>36.656290</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>-0.610323</td>\n",
       "      <td>0.200579</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.195712</td>\n",
       "      <td>2.128935</td>\n",
       "      <td>-7.933036</td>\n",
       "      <td>97.618210</td>\n",
       "      <td>-10.011992</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>0.573047</td>\n",
       "      <td>0.583352</td>\n",
       "      <td>0.195670</td>\n",
       "      <td>152.012192</td>\n",
       "      <td>0.309726</td>\n",
       "      <td>-0.040104</td>\n",
       "      <td>0.599913</td>\n",
       "      <td>189.274338</td>\n",
       "      <td>0.583227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            height        width          sxx          sxy          syy  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.009920     1.145984  -152.410980    95.806030  -147.582855   \n",
       "std       0.031200     0.296800    65.652687     8.517452    30.211641   \n",
       "min       0.000003     1.000214  -198.643585     6.414491  -159.945221   \n",
       "25%       0.000003     1.000214  -198.643585    97.618210  -159.945221   \n",
       "50%       0.000003     1.000214  -198.643585    97.618210  -159.945221   \n",
       "75%       0.000003     1.115994  -112.022064    97.618210  -159.945221   \n",
       "max       0.195712     2.128935    -7.933036    97.618210   -10.011992   \n",
       "\n",
       "             sdrop          mud           dc  height_width_ratio  \\\n",
       "count  1000.000000  1000.000000  1000.000000         1000.000000   \n",
       "mean      0.213223     0.469055     0.509479            0.009160   \n",
       "std       0.047509     0.136160     0.120401            0.028974   \n",
       "min       0.200579     0.200045     0.233045            0.000001   \n",
       "25%       0.200579     0.374204     0.464942            0.000003   \n",
       "50%       0.200579     0.568429     0.583352            0.000003   \n",
       "75%       0.200579     0.573047     0.583352            0.000003   \n",
       "max       0.599913     0.573047     0.583352            0.195670   \n",
       "\n",
       "       normal_stress_diff  friction_product  stress_ratio  \\\n",
       "count         1000.000000       1000.000000   1000.000000   \n",
       "mean            -4.828269          0.099655     -0.788919   \n",
       "std             72.507317          0.034780      0.945068   \n",
       "min           -188.631592          0.040125     -9.750129   \n",
       "25%            -38.698364          0.078491     -0.610323   \n",
       "50%            -38.698364          0.114941     -0.610323   \n",
       "75%             36.656290          0.114941     -0.610323   \n",
       "max            152.012192          0.309726     -0.040104   \n",
       "\n",
       "       static_dynamic_friction_diff  stress_diff_dynamic_strength  \\\n",
       "count                   1000.000000                   1000.000000   \n",
       "mean                       0.213223                    165.131363   \n",
       "std                        0.047509                     26.704126   \n",
       "min                        0.200579                     38.410732   \n",
       "25%                        0.200579                    145.352219   \n",
       "50%                        0.200579                    174.424789   \n",
       "75%                        0.200579                    189.274338   \n",
       "max                        0.599913                    189.274338   \n",
       "\n",
       "       normalized_dc  \n",
       "count    1000.000000  \n",
       "mean        0.466428  \n",
       "std         0.139873  \n",
       "min         0.109466  \n",
       "25%         0.350090  \n",
       "50%         0.552838  \n",
       "75%         0.583227  \n",
       "max         0.583227  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_generated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.109851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.128231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.311787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.047339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.137824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.192418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.398238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            reward\n",
       "count  1000.000000\n",
       "mean      1.109851\n",
       "std       0.128231\n",
       "min       0.311787\n",
       "25%       1.047339\n",
       "50%       1.137824\n",
       "75%       1.192418\n",
       "max       1.398238"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rewards = pd.DataFrame(rewards_array, columns=['reward'])\n",
    "df_rewards.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f328a11418f0450ba4349acebea428f7\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f328a11418f0450ba4349acebea428f7\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f328a11418f0450ba4349acebea428f7\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-afed30f8573f11c3d4109fb926d77b74\"}, \"mark\": \"bar\", \"encoding\": {\"x\": {\"bin\": {\"maxbins\": 100}, \"field\": \"reward\", \"type\": \"quantitative\"}, \"y\": {\"aggregate\": \"count\", \"type\": \"quantitative\"}}, \"height\": 400, \"selection\": {\"selector001\": {\"type\": \"interval\", \"bind\": \"scales\", \"encodings\": [\"x\", \"y\"]}}, \"width\": 600, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-afed30f8573f11c3d4109fb926d77b74\": [{\"reward\": 0.7634597420692444}, {\"reward\": 1.075488805770874}, {\"reward\": 1.1009067296981812}, {\"reward\": 1.2226392030715942}, {\"reward\": 1.2279131412506104}, {\"reward\": 1.2115328311920166}, {\"reward\": 1.1030312776565552}, {\"reward\": 1.1520015001296997}, {\"reward\": 0.9948086142539978}, {\"reward\": 0.9290153980255127}, {\"reward\": 0.9671488404273987}, {\"reward\": 1.2421910762786865}, {\"reward\": 1.0834685564041138}, {\"reward\": 1.0792295932769775}, {\"reward\": 1.0539205074310303}, {\"reward\": 0.5776405334472656}, {\"reward\": 1.0451135635375977}, {\"reward\": 1.0417513847351074}, {\"reward\": 1.1790685653686523}, {\"reward\": 0.9298646450042725}, {\"reward\": 0.9492379426956177}, {\"reward\": 1.043338418006897}, {\"reward\": 1.1078349351882935}, {\"reward\": 1.2200912237167358}, {\"reward\": 1.1704014539718628}, {\"reward\": 1.123539924621582}, {\"reward\": 1.0641112327575684}, {\"reward\": 1.1543939113616943}, {\"reward\": 1.1790685653686523}, {\"reward\": 1.2277950048446655}, {\"reward\": 1.0557887554168701}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1442711353302002}, {\"reward\": 1.1693947315216064}, {\"reward\": 1.1910536289215088}, {\"reward\": 1.2066072225570679}, {\"reward\": 0.8478004932403564}, {\"reward\": 1.0279244184494019}, {\"reward\": 1.2308458089828491}, {\"reward\": 1.1789871454238892}, {\"reward\": 1.1650500297546387}, {\"reward\": 1.2237133979797363}, {\"reward\": 1.0077781677246094}, {\"reward\": 0.8638964891433716}, {\"reward\": 1.110099196434021}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2093937397003174}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1734143495559692}, {\"reward\": 0.956322193145752}, {\"reward\": 0.9978460073471069}, {\"reward\": 1.1386419534683228}, {\"reward\": 1.2613821029663086}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1090021133422852}, {\"reward\": 1.2882193326950073}, {\"reward\": 1.0198060274124146}, {\"reward\": 1.1312867403030396}, {\"reward\": 1.1422241926193237}, {\"reward\": 1.1021138429641724}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.988517701625824}, {\"reward\": 1.077341914176941}, {\"reward\": 1.086653232574463}, {\"reward\": 0.8610620498657227}, {\"reward\": 1.2402459383010864}, {\"reward\": 1.1755759716033936}, {\"reward\": 1.1446683406829834}, {\"reward\": 1.1691863536834717}, {\"reward\": 1.1191060543060303}, {\"reward\": 1.0314847230911255}, {\"reward\": 1.2518266439437866}, {\"reward\": 1.009729266166687}, {\"reward\": 1.123539924621582}, {\"reward\": 1.1634031534194946}, {\"reward\": 1.1066210269927979}, {\"reward\": 1.0672413110733032}, {\"reward\": 0.9004578590393066}, {\"reward\": 1.2455389499664307}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0206279754638672}, {\"reward\": 1.1745672225952148}, {\"reward\": 1.2276145219802856}, {\"reward\": 1.359802484512329}, {\"reward\": 1.1772575378417969}, {\"reward\": 1.0238170623779297}, {\"reward\": 1.1580227613449097}, {\"reward\": 1.0718828439712524}, {\"reward\": 0.9294087290763855}, {\"reward\": 1.095368504524231}, {\"reward\": 1.1912654638290405}, {\"reward\": 1.102002501487732}, {\"reward\": 0.925409734249115}, {\"reward\": 1.2378294467926025}, {\"reward\": 1.1006587743759155}, {\"reward\": 1.045162558555603}, {\"reward\": 0.9915183186531067}, {\"reward\": 1.1185699701309204}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0525689125061035}, {\"reward\": 1.243303894996643}, {\"reward\": 1.1586922407150269}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0264273881912231}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1982743740081787}, {\"reward\": 1.1481255292892456}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1093103885650635}, {\"reward\": 0.9858366250991821}, {\"reward\": 0.797443151473999}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2098230123519897}, {\"reward\": 1.0672413110733032}, {\"reward\": 0.9885812401771545}, {\"reward\": 1.015575885772705}, {\"reward\": 1.1412408351898193}, {\"reward\": 0.9778617024421692}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.612468421459198}, {\"reward\": 1.2091772556304932}, {\"reward\": 1.254516363143921}, {\"reward\": 1.0049329996109009}, {\"reward\": 1.0635343790054321}, {\"reward\": 1.2369650602340698}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.033771276473999}, {\"reward\": 1.1480296850204468}, {\"reward\": 1.1294071674346924}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.9126341938972473}, {\"reward\": 0.8373041749000549}, {\"reward\": 1.1458855867385864}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.0161291360855103}, {\"reward\": 1.1418044567108154}, {\"reward\": 1.1766377687454224}, {\"reward\": 1.1115776300430298}, {\"reward\": 1.0119513273239136}, {\"reward\": 1.0621280670166016}, {\"reward\": 1.1465582847595215}, {\"reward\": 0.8183926939964294}, {\"reward\": 0.8572822213172913}, {\"reward\": 1.1351332664489746}, {\"reward\": 1.226703405380249}, {\"reward\": 1.2697473764419556}, {\"reward\": 1.2358957529067993}, {\"reward\": 1.1762388944625854}, {\"reward\": 1.072344183921814}, {\"reward\": 1.2531100511550903}, {\"reward\": 1.085068702697754}, {\"reward\": 1.1740961074829102}, {\"reward\": 0.9930218458175659}, {\"reward\": 0.9385822415351868}, {\"reward\": 0.9982567429542542}, {\"reward\": 1.284297227859497}, {\"reward\": 1.2343840599060059}, {\"reward\": 1.041811466217041}, {\"reward\": 1.1583447456359863}, {\"reward\": 1.2236433029174805}, {\"reward\": 0.9859904646873474}, {\"reward\": 0.8005710244178772}, {\"reward\": 1.1685363054275513}, {\"reward\": 0.9194945693016052}, {\"reward\": 1.0298882722854614}, {\"reward\": 1.166278600692749}, {\"reward\": 1.1456612348556519}, {\"reward\": 1.0013139247894287}, {\"reward\": 1.0199663639068604}, {\"reward\": 1.1080478429794312}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.203923225402832}, {\"reward\": 1.1106075048446655}, {\"reward\": 0.934690535068512}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0012258291244507}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0327427387237549}, {\"reward\": 0.7921349406242371}, {\"reward\": 1.2457445859909058}, {\"reward\": 1.0740418434143066}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1845643520355225}, {\"reward\": 1.1016052961349487}, {\"reward\": 1.1095503568649292}, {\"reward\": 1.1638964414596558}, {\"reward\": 1.0291132926940918}, {\"reward\": 1.1166292428970337}, {\"reward\": 1.0825300216674805}, {\"reward\": 1.1414035558700562}, {\"reward\": 1.0907649993896484}, {\"reward\": 1.0234824419021606}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.005325436592102}, {\"reward\": 1.1702218055725098}, {\"reward\": 1.2599674463272095}, {\"reward\": 1.247112512588501}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1695752143859863}, {\"reward\": 1.1392532587051392}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1110974550247192}, {\"reward\": 1.3075847625732422}, {\"reward\": 1.1604993343353271}, {\"reward\": 0.9368562698364258}, {\"reward\": 1.2580915689468384}, {\"reward\": 1.2945051193237305}, {\"reward\": 1.192109227180481}, {\"reward\": 1.2357877492904663}, {\"reward\": 1.0656852722167969}, {\"reward\": 1.1462163925170898}, {\"reward\": 1.2717422246932983}, {\"reward\": 1.321272611618042}, {\"reward\": 1.116072177886963}, {\"reward\": 1.2062925100326538}, {\"reward\": 1.0979959964752197}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1150412559509277}, {\"reward\": 1.2368106842041016}, {\"reward\": 1.096218228340149}, {\"reward\": 1.2376043796539307}, {\"reward\": 0.9791415929794312}, {\"reward\": 1.202163577079773}, {\"reward\": 0.9806331992149353}, {\"reward\": 1.108628273010254}, {\"reward\": 1.2954636812210083}, {\"reward\": 1.13526451587677}, {\"reward\": 1.028686285018921}, {\"reward\": 1.3616516590118408}, {\"reward\": 1.1425951719284058}, {\"reward\": 1.096396565437317}, {\"reward\": 1.1555017232894897}, {\"reward\": 1.0832101106643677}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.2468879222869873}, {\"reward\": 1.1288700103759766}, {\"reward\": 1.0411301851272583}, {\"reward\": 0.9905039668083191}, {\"reward\": 1.2444649934768677}, {\"reward\": 0.9459963440895081}, {\"reward\": 0.9543665647506714}, {\"reward\": 1.1805989742279053}, {\"reward\": 1.044609785079956}, {\"reward\": 1.074609637260437}, {\"reward\": 1.2104154825210571}, {\"reward\": 1.2416082620620728}, {\"reward\": 1.2162258625030518}, {\"reward\": 1.0676853656768799}, {\"reward\": 1.133150339126587}, {\"reward\": 1.2159968614578247}, {\"reward\": 1.145898699760437}, {\"reward\": 1.0069838762283325}, {\"reward\": 0.923549234867096}, {\"reward\": 1.2374786138534546}, {\"reward\": 0.6563838124275208}, {\"reward\": 0.843520998954773}, {\"reward\": 1.1337093114852905}, {\"reward\": 1.1102722883224487}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.8433533906936646}, {\"reward\": 1.2158266305923462}, {\"reward\": 1.2225879430770874}, {\"reward\": 1.2699711322784424}, {\"reward\": 1.1687060594558716}, {\"reward\": 1.1699602603912354}, {\"reward\": 1.145898699760437}, {\"reward\": 1.0580638647079468}, {\"reward\": 1.2199392318725586}, {\"reward\": 1.0852625370025635}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.3018771409988403}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2298504114151}, {\"reward\": 1.208349347114563}, {\"reward\": 1.0234489440917969}, {\"reward\": 1.2121503353118896}, {\"reward\": 0.9369682669639587}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1394692659378052}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.203923225402832}, {\"reward\": 1.1752471923828125}, {\"reward\": 1.1250383853912354}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1261608600616455}, {\"reward\": 1.1439554691314697}, {\"reward\": 1.055770754814148}, {\"reward\": 1.1001096963882446}, {\"reward\": 1.2324156761169434}, {\"reward\": 1.0327401161193848}, {\"reward\": 0.8955124616622925}, {\"reward\": 1.2291910648345947}, {\"reward\": 1.1262365579605103}, {\"reward\": 1.0630676746368408}, {\"reward\": 0.9535019397735596}, {\"reward\": 1.1214498281478882}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.9858366250991821}, {\"reward\": 1.1790488958358765}, {\"reward\": 1.2444736957550049}, {\"reward\": 1.0714900493621826}, {\"reward\": 1.2626845836639404}, {\"reward\": 0.9767101407051086}, {\"reward\": 1.1323884725570679}, {\"reward\": 1.2378294467926025}, {\"reward\": 1.1998754739761353}, {\"reward\": 1.1470555067062378}, {\"reward\": 1.042206048965454}, {\"reward\": 1.011379361152649}, {\"reward\": 0.9858366250991821}, {\"reward\": 1.123197078704834}, {\"reward\": 1.203923225402832}, {\"reward\": 1.1171648502349854}, {\"reward\": 1.1219358444213867}, {\"reward\": 1.213348388671875}, {\"reward\": 1.3150147199630737}, {\"reward\": 1.0420578718185425}, {\"reward\": 1.242678165435791}, {\"reward\": 1.2622294425964355}, {\"reward\": 1.0791183710098267}, {\"reward\": 1.0886423587799072}, {\"reward\": 1.1573461294174194}, {\"reward\": 1.033957839012146}, {\"reward\": 1.1995456218719482}, {\"reward\": 1.0808722972869873}, {\"reward\": 1.1337093114852905}, {\"reward\": 1.2297444343566895}, {\"reward\": 1.1708827018737793}, {\"reward\": 1.3171480894088745}, {\"reward\": 1.1782978773117065}, {\"reward\": 1.2490442991256714}, {\"reward\": 1.1510498523712158}, {\"reward\": 1.0530718564987183}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.155081033706665}, {\"reward\": 1.0466995239257812}, {\"reward\": 1.0839886665344238}, {\"reward\": 0.9145978689193726}, {\"reward\": 1.0471714735031128}, {\"reward\": 0.9380671381950378}, {\"reward\": 1.1223055124282837}, {\"reward\": 1.0586442947387695}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.148174524307251}, {\"reward\": 1.1152015924453735}, {\"reward\": 0.767993152141571}, {\"reward\": 1.0764776468276978}, {\"reward\": 1.1470402479171753}, {\"reward\": 1.2357683181762695}, {\"reward\": 0.9372872710227966}, {\"reward\": 1.1755058765411377}, {\"reward\": 0.9645766615867615}, {\"reward\": 1.2450926303863525}, {\"reward\": 1.0328571796417236}, {\"reward\": 1.1955504417419434}, {\"reward\": 1.172037124633789}, {\"reward\": 1.1681114435195923}, {\"reward\": 1.0402950048446655}, {\"reward\": 0.999534547328949}, {\"reward\": 1.102128505706787}, {\"reward\": 1.2279971837997437}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.055612325668335}, {\"reward\": 1.2612053155899048}, {\"reward\": 0.8982412815093994}, {\"reward\": 1.0087810754776}, {\"reward\": 0.9289681911468506}, {\"reward\": 1.2162258625030518}, {\"reward\": 1.1251344680786133}, {\"reward\": 1.1182111501693726}, {\"reward\": 1.2445530891418457}, {\"reward\": 1.1617896556854248}, {\"reward\": 1.2089673280715942}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.215874195098877}, {\"reward\": 0.72124183177948}, {\"reward\": 1.2004083395004272}, {\"reward\": 1.149308204650879}, {\"reward\": 1.13190758228302}, {\"reward\": 1.1766377687454224}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.990085780620575}, {\"reward\": 1.2030479907989502}, {\"reward\": 1.0021580457687378}, {\"reward\": 1.092941164970398}, {\"reward\": 1.1765756607055664}, {\"reward\": 1.3128658533096313}, {\"reward\": 1.1187926530838013}, {\"reward\": 1.0244604349136353}, {\"reward\": 1.1035919189453125}, {\"reward\": 0.8323649168014526}, {\"reward\": 1.2304959297180176}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.2637945413589478}, {\"reward\": 1.1625642776489258}, {\"reward\": 1.1791948080062866}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2405132055282593}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0016405582427979}, {\"reward\": 1.1066210269927979}, {\"reward\": 1.0337903499603271}, {\"reward\": 0.8582713007926941}, {\"reward\": 1.0721075534820557}, {\"reward\": 0.905791699886322}, {\"reward\": 1.2059824466705322}, {\"reward\": 1.3446531295776367}, {\"reward\": 0.9746652841567993}, {\"reward\": 1.1534978151321411}, {\"reward\": 1.2047176361083984}, {\"reward\": 1.1845643520355225}, {\"reward\": 1.2306405305862427}, {\"reward\": 1.000156044960022}, {\"reward\": 1.2319555282592773}, {\"reward\": 1.056884527206421}, {\"reward\": 1.2805821895599365}, {\"reward\": 1.2336493730545044}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2261782884597778}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0670865774154663}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2370924949645996}, {\"reward\": 0.8929920792579651}, {\"reward\": 1.2090697288513184}, {\"reward\": 1.336456060409546}, {\"reward\": 1.183167576789856}, {\"reward\": 0.9858366250991821}, {\"reward\": 1.0245856046676636}, {\"reward\": 1.1074410676956177}, {\"reward\": 1.1916896104812622}, {\"reward\": 1.0116844177246094}, {\"reward\": 0.9664297699928284}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2422285079956055}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.0205469131469727}, {\"reward\": 0.9673668742179871}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0973211526870728}, {\"reward\": 1.0554006099700928}, {\"reward\": 1.2520681619644165}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2668638229370117}, {\"reward\": 1.304879069328308}, {\"reward\": 1.0154496431350708}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.058525800704956}, {\"reward\": 1.2940884828567505}, {\"reward\": 0.8258076310157776}, {\"reward\": 1.1634031534194946}, {\"reward\": 1.126988172531128}, {\"reward\": 0.7500547170639038}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1625642776489258}, {\"reward\": 1.1721463203430176}, {\"reward\": 1.1354894638061523}, {\"reward\": 1.269464373588562}, {\"reward\": 0.3519570827484131}, {\"reward\": 1.107134461402893}, {\"reward\": 1.2212679386138916}, {\"reward\": 0.9282110333442688}, {\"reward\": 0.9778947234153748}, {\"reward\": 1.116119384765625}, {\"reward\": 1.19264554977417}, {\"reward\": 1.2306405305862427}, {\"reward\": 1.095357060432434}, {\"reward\": 1.2680165767669678}, {\"reward\": 1.1237351894378662}, {\"reward\": 1.1451821327209473}, {\"reward\": 1.0858074426651}, {\"reward\": 1.2562748193740845}, {\"reward\": 1.0083553791046143}, {\"reward\": 1.1546424627304077}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.1304150819778442}, {\"reward\": 1.2401822805404663}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.307753086090088}, {\"reward\": 1.2690531015396118}, {\"reward\": 1.2879348993301392}, {\"reward\": 1.1683707237243652}, {\"reward\": 1.249164342880249}, {\"reward\": 1.1079233884811401}, {\"reward\": 1.1208548545837402}, {\"reward\": 1.0973024368286133}, {\"reward\": 1.2295407056808472}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1553021669387817}, {\"reward\": 0.9589460492134094}, {\"reward\": 1.1625232696533203}, {\"reward\": 1.1827950477600098}, {\"reward\": 1.108139157295227}, {\"reward\": 0.8321097493171692}, {\"reward\": 1.110715389251709}, {\"reward\": 1.3063509464263916}, {\"reward\": 1.1405032873153687}, {\"reward\": 0.9104788899421692}, {\"reward\": 0.9332218170166016}, {\"reward\": 1.2209718227386475}, {\"reward\": 1.1575274467468262}, {\"reward\": 0.9709323644638062}, {\"reward\": 1.3199487924575806}, {\"reward\": 1.0056965351104736}, {\"reward\": 1.2230467796325684}, {\"reward\": 1.0924429893493652}, {\"reward\": 0.3117874264717102}, {\"reward\": 1.1790488958358765}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.9901058077812195}, {\"reward\": 0.9552523493766785}, {\"reward\": 0.9999091029167175}, {\"reward\": 1.1889564990997314}, {\"reward\": 1.217858910560608}, {\"reward\": 0.9932616949081421}, {\"reward\": 1.2178865671157837}, {\"reward\": 0.9740781784057617}, {\"reward\": 1.222499132156372}, {\"reward\": 1.0746662616729736}, {\"reward\": 1.3176459074020386}, {\"reward\": 0.981721818447113}, {\"reward\": 1.0965486764907837}, {\"reward\": 0.978164553642273}, {\"reward\": 1.123678207397461}, {\"reward\": 1.1280604600906372}, {\"reward\": 1.2061128616333008}, {\"reward\": 0.8252347707748413}, {\"reward\": 1.0081017017364502}, {\"reward\": 1.1537262201309204}, {\"reward\": 1.1923424005508423}, {\"reward\": 0.9383147358894348}, {\"reward\": 1.1284059286117554}, {\"reward\": 0.8667107820510864}, {\"reward\": 1.1998754739761353}, {\"reward\": 1.251589298248291}, {\"reward\": 1.14083731174469}, {\"reward\": 1.207732081413269}, {\"reward\": 1.1852220296859741}, {\"reward\": 0.8705611824989319}, {\"reward\": 1.0275412797927856}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.077223777770996}, {\"reward\": 0.7450729012489319}, {\"reward\": 1.1724599599838257}, {\"reward\": 1.237290382385254}, {\"reward\": 1.2291910648345947}, {\"reward\": 0.9580321907997131}, {\"reward\": 1.2106130123138428}, {\"reward\": 1.1499673128128052}, {\"reward\": 1.123539924621582}, {\"reward\": 1.1762505769729614}, {\"reward\": 1.07932448387146}, {\"reward\": 1.0375205278396606}, {\"reward\": 1.1358582973480225}, {\"reward\": 1.2400119304656982}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1698118448257446}, {\"reward\": 1.1537262201309204}, {\"reward\": 1.0288712978363037}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.1749136447906494}, {\"reward\": 1.1705639362335205}, {\"reward\": 1.222499132156372}, {\"reward\": 1.2800391912460327}, {\"reward\": 0.9444736838340759}, {\"reward\": 1.173255205154419}, {\"reward\": 0.9505747556686401}, {\"reward\": 1.166200876235962}, {\"reward\": 1.1481900215148926}, {\"reward\": 0.6093869209289551}, {\"reward\": 1.0020685195922852}, {\"reward\": 1.1248483657836914}, {\"reward\": 1.073458194732666}, {\"reward\": 1.2192435264587402}, {\"reward\": 0.9672241806983948}, {\"reward\": 1.0155056715011597}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.1136078834533691}, {\"reward\": 1.1265192031860352}, {\"reward\": 1.097021460533142}, {\"reward\": 1.0072213411331177}, {\"reward\": 1.1046886444091797}, {\"reward\": 0.9822591543197632}, {\"reward\": 1.1790488958358765}, {\"reward\": 1.2391647100448608}, {\"reward\": 1.1858400106430054}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.282975673675537}, {\"reward\": 0.8237783908843994}, {\"reward\": 1.258683681488037}, {\"reward\": 1.1395303010940552}, {\"reward\": 1.2490098476409912}, {\"reward\": 1.0947110652923584}, {\"reward\": 1.1762388944625854}, {\"reward\": 1.0219765901565552}, {\"reward\": 1.164582371711731}, {\"reward\": 1.2291556596755981}, {\"reward\": 0.8149777054786682}, {\"reward\": 1.1185367107391357}, {\"reward\": 1.2435733079910278}, {\"reward\": 1.3230551481246948}, {\"reward\": 1.1079057455062866}, {\"reward\": 1.1337919235229492}, {\"reward\": 1.1304583549499512}, {\"reward\": 0.9726970791816711}, {\"reward\": 1.2162258625030518}, {\"reward\": 1.0950069427490234}, {\"reward\": 1.2393053770065308}, {\"reward\": 1.1317288875579834}, {\"reward\": 1.2351232767105103}, {\"reward\": 1.2428988218307495}, {\"reward\": 1.0875335931777954}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2614949941635132}, {\"reward\": 1.0948282480239868}, {\"reward\": 1.2540533542633057}, {\"reward\": 1.233614444732666}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1446056365966797}, {\"reward\": 0.925554096698761}, {\"reward\": 1.0552902221679688}, {\"reward\": 1.1769359111785889}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.3173290491104126}, {\"reward\": 1.324476718902588}, {\"reward\": 0.7735726237297058}, {\"reward\": 1.3017082214355469}, {\"reward\": 0.9493200778961182}, {\"reward\": 1.2124384641647339}, {\"reward\": 1.04840886592865}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1078029870986938}, {\"reward\": 1.1980417966842651}, {\"reward\": 1.1094468832015991}, {\"reward\": 0.9299811720848083}, {\"reward\": 0.44660767912864685}, {\"reward\": 1.2724833488464355}, {\"reward\": 1.157744288444519}, {\"reward\": 0.9858366250991821}, {\"reward\": 1.2191963195800781}, {\"reward\": 0.5833637118339539}, {\"reward\": 1.0106921195983887}, {\"reward\": 1.132939338684082}, {\"reward\": 1.108352541923523}, {\"reward\": 1.2284691333770752}, {\"reward\": 1.2339909076690674}, {\"reward\": 1.125127911567688}, {\"reward\": 1.2078967094421387}, {\"reward\": 1.0949152708053589}, {\"reward\": 1.1016610860824585}, {\"reward\": 0.821200966835022}, {\"reward\": 1.3348894119262695}, {\"reward\": 1.2784907817840576}, {\"reward\": 1.2252633571624756}, {\"reward\": 1.1331003904342651}, {\"reward\": 1.1727666854858398}, {\"reward\": 1.1997814178466797}, {\"reward\": 1.1405420303344727}, {\"reward\": 1.313513994216919}, {\"reward\": 0.9679047465324402}, {\"reward\": 0.8046917915344238}, {\"reward\": 0.973151683807373}, {\"reward\": 1.1791948080062866}, {\"reward\": 1.1614046096801758}, {\"reward\": 1.2175986766815186}, {\"reward\": 1.0243803262710571}, {\"reward\": 1.1472769975662231}, {\"reward\": 1.0380842685699463}, {\"reward\": 1.2089569568634033}, {\"reward\": 1.163480520248413}, {\"reward\": 1.0023815631866455}, {\"reward\": 1.1386998891830444}, {\"reward\": 1.2637063264846802}, {\"reward\": 0.9469616413116455}, {\"reward\": 1.1388651132583618}, {\"reward\": 0.8891484141349792}, {\"reward\": 0.9664496183395386}, {\"reward\": 1.2303786277770996}, {\"reward\": 1.2550935745239258}, {\"reward\": 1.1268547773361206}, {\"reward\": 1.2612333297729492}, {\"reward\": 1.132939338684082}, {\"reward\": 1.0947262048721313}, {\"reward\": 1.2870768308639526}, {\"reward\": 1.036496639251709}, {\"reward\": 0.905791699886322}, {\"reward\": 1.129457712173462}, {\"reward\": 1.2419054508209229}, {\"reward\": 1.1004809141159058}, {\"reward\": 0.9858366250991821}, {\"reward\": 1.2450001239776611}, {\"reward\": 1.2402527332305908}, {\"reward\": 1.0780874490737915}, {\"reward\": 1.0198060274124146}, {\"reward\": 1.123539924621582}, {\"reward\": 1.157737135887146}, {\"reward\": 1.1200573444366455}, {\"reward\": 1.1736936569213867}, {\"reward\": 1.1290357112884521}, {\"reward\": 1.2084991931915283}, {\"reward\": 1.2450318336486816}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2694144248962402}, {\"reward\": 1.1261626482009888}, {\"reward\": 0.8875245451927185}, {\"reward\": 1.0270992517471313}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.7730207443237305}, {\"reward\": 1.1168997287750244}, {\"reward\": 1.1304343938827515}, {\"reward\": 1.2059824466705322}, {\"reward\": 0.9371819496154785}, {\"reward\": 1.0971550941467285}, {\"reward\": 1.1164051294326782}, {\"reward\": 1.1472587585449219}, {\"reward\": 1.2456562519073486}, {\"reward\": 1.1344900131225586}, {\"reward\": 0.8168450593948364}, {\"reward\": 1.2287368774414062}, {\"reward\": 1.123539924621582}, {\"reward\": 0.9484213590621948}, {\"reward\": 0.9976276159286499}, {\"reward\": 1.0280054807662964}, {\"reward\": 1.041904330253601}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2515723705291748}, {\"reward\": 1.1362557411193848}, {\"reward\": 1.1056902408599854}, {\"reward\": 1.1586552858352661}, {\"reward\": 1.2357683181762695}, {\"reward\": 0.796252429485321}, {\"reward\": 1.0688060522079468}, {\"reward\": 1.1448770761489868}, {\"reward\": 1.107134461402893}, {\"reward\": 0.7864957451820374}, {\"reward\": 1.055539608001709}, {\"reward\": 1.0984803438186646}, {\"reward\": 1.1786479949951172}, {\"reward\": 1.123539924621582}, {\"reward\": 1.233515739440918}, {\"reward\": 1.2026617527008057}, {\"reward\": 1.1657969951629639}, {\"reward\": 1.0152758359909058}, {\"reward\": 1.0170272588729858}, {\"reward\": 1.150320053100586}, {\"reward\": 1.0705474615097046}, {\"reward\": 0.4136611223220825}, {\"reward\": 1.1997814178466797}, {\"reward\": 1.0060228109359741}, {\"reward\": 1.3136670589447021}, {\"reward\": 1.176239013671875}, {\"reward\": 1.0700727701187134}, {\"reward\": 1.0096263885498047}, {\"reward\": 1.176239013671875}, {\"reward\": 1.1245918273925781}, {\"reward\": 1.0204986333847046}, {\"reward\": 1.104681372642517}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.1997480392456055}, {\"reward\": 1.0791250467300415}, {\"reward\": 1.1027441024780273}, {\"reward\": 0.9043467044830322}, {\"reward\": 1.1163394451141357}, {\"reward\": 1.206936001777649}, {\"reward\": 1.177753210067749}, {\"reward\": 1.2487224340438843}, {\"reward\": 1.123539924621582}, {\"reward\": 1.1543939113616943}, {\"reward\": 1.0902576446533203}, {\"reward\": 1.147633671760559}, {\"reward\": 1.1132957935333252}, {\"reward\": 0.9953463077545166}, {\"reward\": 1.0870152711868286}, {\"reward\": 1.1142675876617432}, {\"reward\": 0.9540359377861023}, {\"reward\": 0.8451226949691772}, {\"reward\": 1.1846848726272583}, {\"reward\": 1.204776406288147}, {\"reward\": 0.9576941132545471}, {\"reward\": 1.2401533126831055}, {\"reward\": 1.1335406303405762}, {\"reward\": 1.0334194898605347}, {\"reward\": 1.1473000049591064}, {\"reward\": 1.0473945140838623}, {\"reward\": 1.0269758701324463}, {\"reward\": 1.1357873678207397}, {\"reward\": 1.0122833251953125}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.3251323699951172}, {\"reward\": 0.9665929675102234}, {\"reward\": 1.140271544456482}, {\"reward\": 0.8070593476295471}, {\"reward\": 1.2141501903533936}, {\"reward\": 1.0830055475234985}, {\"reward\": 1.1473726034164429}, {\"reward\": 1.0271105766296387}, {\"reward\": 1.2695125341415405}, {\"reward\": 1.1228739023208618}, {\"reward\": 1.1643353700637817}, {\"reward\": 1.123539924621582}, {\"reward\": 0.9891531467437744}, {\"reward\": 0.9679303765296936}, {\"reward\": 1.1078009605407715}, {\"reward\": 1.0714973211288452}, {\"reward\": 1.2348884344100952}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.9068365693092346}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1826014518737793}, {\"reward\": 1.2108856439590454}, {\"reward\": 1.2014093399047852}, {\"reward\": 1.2672702074050903}, {\"reward\": 1.176239013671875}, {\"reward\": 1.0007524490356445}, {\"reward\": 0.9222192168235779}, {\"reward\": 1.2144601345062256}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1096467971801758}, {\"reward\": 1.1761326789855957}, {\"reward\": 1.0461677312850952}, {\"reward\": 1.1138583421707153}, {\"reward\": 1.1005209684371948}, {\"reward\": 1.3982383012771606}, {\"reward\": 0.7691779136657715}, {\"reward\": 0.7225832343101501}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1497188806533813}, {\"reward\": 1.259522795677185}, {\"reward\": 1.0295922756195068}, {\"reward\": 1.0775492191314697}, {\"reward\": 0.9475919008255005}, {\"reward\": 1.246427059173584}, {\"reward\": 1.1476337909698486}, {\"reward\": 1.0911532640457153}, {\"reward\": 1.2478864192962646}, {\"reward\": 1.1828930377960205}, {\"reward\": 1.1802061796188354}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.879572331905365}, {\"reward\": 1.0637136697769165}, {\"reward\": 1.1753672361373901}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0546351671218872}, {\"reward\": 0.9957680106163025}, {\"reward\": 1.2685338258743286}, {\"reward\": 1.2478864192962646}, {\"reward\": 1.0909978151321411}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0843291282653809}, {\"reward\": 1.153053879737854}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0840339660644531}, {\"reward\": 1.1165701150894165}, {\"reward\": 1.1946794986724854}, {\"reward\": 1.1140360832214355}, {\"reward\": 1.214888095855713}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1013307571411133}, {\"reward\": 1.271399974822998}, {\"reward\": 0.9990105032920837}, {\"reward\": 1.239985466003418}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.182123064994812}, {\"reward\": 1.2070103883743286}, {\"reward\": 0.8132059574127197}, {\"reward\": 1.3925120830535889}, {\"reward\": 1.1030391454696655}, {\"reward\": 1.2271028757095337}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2339041233062744}, {\"reward\": 1.2373260259628296}, {\"reward\": 1.1491456031799316}, {\"reward\": 1.2391843795776367}, {\"reward\": 1.17618727684021}, {\"reward\": 1.1791948080062866}, {\"reward\": 1.1966958045959473}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0654563903808594}, {\"reward\": 0.8495565056800842}, {\"reward\": 1.107134461402893}, {\"reward\": 1.2282953262329102}, {\"reward\": 1.1167786121368408}, {\"reward\": 1.0024054050445557}, {\"reward\": 1.1033332347869873}, {\"reward\": 1.1245850324630737}, {\"reward\": 1.3253222703933716}, {\"reward\": 0.8898186683654785}, {\"reward\": 1.1062285900115967}, {\"reward\": 1.1812732219696045}, {\"reward\": 0.7412002682685852}, {\"reward\": 1.108343482017517}, {\"reward\": 1.2631155252456665}, {\"reward\": 1.2799670696258545}, {\"reward\": 1.2048561573028564}, {\"reward\": 1.0402195453643799}, {\"reward\": 1.241271734237671}, {\"reward\": 1.263893723487854}, {\"reward\": 0.9249798059463501}, {\"reward\": 1.047896385192871}, {\"reward\": 0.9121105670928955}, {\"reward\": 1.1323304176330566}, {\"reward\": 1.1735739707946777}, {\"reward\": 0.9271401762962341}, {\"reward\": 1.0654563903808594}, {\"reward\": 1.237808346748352}, {\"reward\": 0.9774888753890991}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1750401258468628}, {\"reward\": 1.0694962739944458}, {\"reward\": 1.0768647193908691}, {\"reward\": 1.1856956481933594}, {\"reward\": 1.1802058219909668}, {\"reward\": 1.128623604774475}, {\"reward\": 1.0971845388412476}, {\"reward\": 1.1378241777420044}, {\"reward\": 0.8853643536567688}, {\"reward\": 0.9530012607574463}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.2458813190460205}, {\"reward\": 1.1253520250320435}, {\"reward\": 1.1834715604782104}, {\"reward\": 1.0312319993972778}, {\"reward\": 1.1772713661193848}, {\"reward\": 0.9243748784065247}, {\"reward\": 1.1964930295944214}, {\"reward\": 1.238721251487732}, {\"reward\": 1.1350009441375732}, {\"reward\": 1.1106804609298706}, {\"reward\": 1.021692156791687}, {\"reward\": 1.1282646656036377}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.0129212141036987}, {\"reward\": 1.2162258625030518}, {\"reward\": 1.1470555067062378}, {\"reward\": 1.1784249544143677}, {\"reward\": 1.2518144845962524}, {\"reward\": 1.0672413110733032}, {\"reward\": 0.9638630151748657}, {\"reward\": 1.215596318244934}, {\"reward\": 1.2760881185531616}, {\"reward\": 1.2171677350997925}, {\"reward\": 0.9690182209014893}, {\"reward\": 1.124956488609314}, {\"reward\": 1.2385165691375732}, {\"reward\": 1.1206486225128174}, {\"reward\": 1.1184346675872803}, {\"reward\": 1.105454683303833}, {\"reward\": 1.2351232767105103}, {\"reward\": 1.0501866340637207}, {\"reward\": 1.2088994979858398}, {\"reward\": 1.0173262357711792}, {\"reward\": 1.0995631217956543}, {\"reward\": 1.1519092321395874}, {\"reward\": 1.1656181812286377}, {\"reward\": 1.1791948080062866}, {\"reward\": 1.3323116302490234}, {\"reward\": 1.1791107654571533}, {\"reward\": 1.2512643337249756}, {\"reward\": 1.1426397562026978}, {\"reward\": 0.5721153616905212}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.1484955549240112}, {\"reward\": 0.9788916110992432}, {\"reward\": 1.0463868379592896}, {\"reward\": 1.1730962991714478}, {\"reward\": 0.9578213095664978}, {\"reward\": 1.1682218313217163}, {\"reward\": 1.15926992893219}, {\"reward\": 1.1497188806533813}, {\"reward\": 1.2463867664337158}, {\"reward\": 1.2040412425994873}, {\"reward\": 1.1368048191070557}, {\"reward\": 1.0672413110733032}, {\"reward\": 1.114107370376587}, {\"reward\": 1.2519012689590454}, {\"reward\": 0.9914624094963074}, {\"reward\": 1.1554194688796997}, {\"reward\": 1.0096263885498047}, {\"reward\": 1.1960241794586182}, {\"reward\": 0.9858366250991821}, {\"reward\": 1.1956290006637573}, {\"reward\": 1.2098437547683716}, {\"reward\": 1.2223354578018188}, {\"reward\": 1.1053646802902222}, {\"reward\": 1.1378241777420044}, {\"reward\": 1.140903115272522}, {\"reward\": 1.0800669193267822}, {\"reward\": 0.9968298673629761}, {\"reward\": 1.2510979175567627}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot distribution plot using altaire\n",
    "alt.Chart(df_rewards).mark_bar().encode(\n",
    "    alt.X('reward', bin=alt.Bin(maxbins=100)),\n",
    "    y='count()',\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_train, df_generated], ignore_index=True)\n",
    "combined_df['data_type'] = ['train'] * len(df_train) + ['generated'] * len(df_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution plot using altaire\n",
    "alt.Chart(combined_df).mark_bar().encode(\n",
    "    alt.X('width', bin=alt.Bin(maxbins=100)),\n",
    "    y='count()',\n",
    "    color='data_type'\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generated['rewards']  = df_rewards['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_generated).mark_rect().encode(\n",
    "    alt.X('sdrop', bin=alt.Bin(maxbins=100)),\n",
    "    alt.Y('width', bin=alt.Bin(maxbins=100)),\n",
    "    alt.Color('rewards', scale=alt.Scale(scheme='redyellowblue'))\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the parameters of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# Define the objective function to optimize\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    input_noise = torch.randn(1, 100).to(device)\n",
    "    generator_model.eval()\n",
    "    generator_output = generator_model(input_noise)\n",
    "    generator_output = generator_output.squeeze(\n",
    "        0).detach().cpu().numpy().reshape(1, -1)\n",
    "    df_generated = process_for_supervised_model(generator_output)\n",
    "    reward = supervised_model.predict(df_generated)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the objective function for a fixed number of trials\n",
    "n_trials = 1000\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameter settings and reward found\n",
    "best_params = study.best_params\n",
    "best_reward = study.best_value\n",
    "print(f\"Best parameter settings: {best_params}\")\n",
    "print(f\"Best reward: {best_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
