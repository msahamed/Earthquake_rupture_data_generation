{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import gym\n",
    "from stable_baselines3 import PPO, A2C, DQN, SAC, TD3\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "import altair as alt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "random_state = 6\n",
    "np.random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape (1600, 9) and test data shape (400, 9)\n"
     ]
    }
   ],
   "source": [
    "## look data with pandas\n",
    "train_file = \"data/rupturemodel_train.txt\"\n",
    "val_file = \"data/rupturemodel_validate.txt\"\n",
    "test_file = \"data/rupturemodel_test.txt\"\n",
    "\n",
    "df_train= pd.read_csv(train_file, sep=\" \", header = None)\n",
    "df_val= pd.read_csv(val_file, sep=\" \", header = None)\n",
    "df_test= pd.read_csv(test_file, sep=\" \", header = None)\n",
    "\n",
    "columns =  ['height', 'width', 'sxx', 'sxy', 'syy', 'sdrop', 'mud', 'dc', 'label']\n",
    "df_train.columns = columns\n",
    "df_val.columns = columns\n",
    "df_test.columns = columns\n",
    "\n",
    "frames = [df_train, df_val]\n",
    "df_train = pd.concat(frames)\n",
    "print('train data shape {} and test data shape {}'.format(np.shape(df_train), np.shape(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_new = df.copy()\n",
    "    # Create new features\n",
    "    df_new['height_width_ratio'] = df_new['height'] / df_new['width']\n",
    "    df_new['normal_stress_diff'] = df_new['sxx'] - df_new['syy']\n",
    "    df_new['friction_product'] = df_new['mud'] * (df_new['sdrop'])\n",
    "    df_new['stress_ratio'] = df_new['sxy'] / df_new['syy']\n",
    "    df_new['static_dynamic_friction_diff'] = (\n",
    "        df_new['mud'] + df_new['sdrop']) - df_new['mud']\n",
    "    df_new['stress_diff_dynamic_strength'] = df_new['sxy'] - \\\n",
    "        (df_new['syy'] * df_new['mud'])\n",
    "    df_new['normalized_dc'] = df_new['dc'] / df_new['width']\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"data/rupturemodel_train.txt\"\n",
    "columns = ['height', 'width', 'sxx', 'sxy',\n",
    "           'syy', 'sdrop', 'mud', 'dc', 'label']\n",
    "df_train = pd.read_csv(train_file, sep=\" \", header=None)\n",
    "df_train.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your reinforcement learning environment\n",
    "from typing import List\n",
    "\n",
    "class GeneratorEnv(gym.Env):\n",
    "    def __init__(self, supervised_model):\n",
    "        super(GeneratorEnv, self).__init__()\n",
    "        self.supervised_model = supervised_model\n",
    "        self.input_size = 100\n",
    "        self.scaler = joblib.load('./models/scaler.pkl')\n",
    "        self.state = torch.randn(100).to(device)\n",
    "        self.action_space = gym.spaces.Box( low = 0, high = 1, shape = (8,), dtype = np.float32)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-np.inf, high=np.inf, shape=(100,), dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        self.state = torch.randn(1, self.input_size).to(device)\n",
    "        processed_data = self.process_for_supervised_model(np.array(action))\n",
    "        reward = self.supervised_model.predict(processed_data)\n",
    "        done = False\n",
    "        info = {}\n",
    "        return self.state.cpu().numpy(), reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = torch.randn(100).to(device)\n",
    "        return self.state.cpu().numpy()\n",
    "\n",
    "    def process_for_supervised_model(self, generated_data: np.array) -> np.array:\n",
    "        # Process the generated data to make it compatible with the supervised model\n",
    "        columns = ['height', 'width', 'sxx',\n",
    "                   'sxy', 'syy', 'sdrop', 'mud', 'dc']\n",
    "        de_normalized = self.scaler.inverse_transform(\n",
    "            generated_data.reshape(1, -1))  # Reshape to a 2D array\n",
    "        df = pd.DataFrame(de_normalized, columns=columns)\n",
    "        df = create_new_features(df)\n",
    "        return df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the custom environment\n",
    "supervised_model = lgb.Booster(model_file='./models/best_supervised_model.txt')\n",
    "env = DummyVecEnv([lambda: GeneratorEnv(supervised_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f654c4fda30>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the generator using PPO\n",
    "model_name = 'rl_model_ppo'\n",
    "model = PPO('MlpPolicy', env,\n",
    "            verbose=0,\n",
    "            tensorboard_log=\"./logs/rl_logs/\")\n",
    "model.learn(total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rl_model_ppo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/rl_model_ppo_env.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Save the model\n",
    "model.save(f'./models/{model_name}')\n",
    "\n",
    "### Save the environment\n",
    "joblib.dump(env, f'./models/{model_name}_env.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the model\n",
    "loaded_model = PPO.load(f'./models/{model_name}')\n",
    "\n",
    "### Load the environment\n",
    "loaded_env = joblib.load(f'./models/{model_name}_env.joblib')\n",
    "loaded_model.set_env(loaded_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=100, out_features=64, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=64, out_features=8, bias=True)\n",
       "  (value_net): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loaded_model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_array = []\n",
    "generated_data = []\n",
    "obs = loaded_env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = loaded_model.predict(obs)\n",
    "    obs, rewards, dones, info = loaded_env.step(action)\n",
    "    generated_data.append(list(action[0]))\n",
    "    rewards_array.append(rewards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Process the generated data to make it compatible with the supervised model\n",
    "scaler = joblib.load('./models/scaler.pkl')\n",
    "def process_for_supervised_model(generated_data):\n",
    "    # Process the generated data to make it compatible with the supervised model\n",
    "    columns = ['height', 'width', 'sxx',\n",
    "               'sxy', 'syy', 'sdrop', 'mud', 'dc']\n",
    "    de_normalized = scaler.inverse_transform(generated_data)  # Reshape to a 2D array\n",
    "    df = pd.DataFrame(de_normalized, columns=columns)\n",
    "    df = create_new_features(df)\n",
    "    return df\n",
    "\n",
    "data = np.array(generated_data)\n",
    "df_generated = process_for_supervised_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['height', 'width', 'sxx',\n",
    "           'sxy', 'syy', 'sdrop', 'mud', 'dc']\n",
    "df_generated[columns].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generated.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rewards = pd.DataFrame(rewards_array, columns=['reward'])\n",
    "df_rewards.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution plot using altaire\n",
    "alt.Chart(df_rewards).mark_bar().encode(\n",
    "    alt.X('reward', bin=alt.Bin(maxbins=100)),\n",
    "    y='count()',\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_train, df_generated], ignore_index=True)\n",
    "combined_df['data_type'] = ['train'] * len(df_train) + ['generated'] * len(df_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution plot using altaire\n",
    "alt.Chart(combined_df).mark_bar().encode(\n",
    "    alt.X('width', bin=alt.Bin(maxbins=100)),\n",
    "    y='count()',\n",
    "    color='data_type'\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generated['rewards']  = df_rewards['reward']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_generated).mark_rect().encode(\n",
    "    alt.X('sdrop', bin=alt.Bin(maxbins=100)),\n",
    "    alt.Y('width', bin=alt.Bin(maxbins=100)),\n",
    "    alt.Color('rewards', scale=alt.Scale(scheme='redyellowblue'))\n",
    ").properties(\n",
    "    width=600,\n",
    "    height=400\n",
    ").interactive()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the parameters of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# Define the objective function to optimize\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    input_noise = torch.randn(1, 100).to(device)\n",
    "    generator_model.eval()\n",
    "    generator_output = generator_model(input_noise)\n",
    "    generator_output = generator_output.squeeze(\n",
    "        0).detach().cpu().numpy().reshape(1, -1)\n",
    "    df_generated = process_for_supervised_model(generator_output)\n",
    "    reward = supervised_model.predict(df_generated)\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimization study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize the objective function for a fixed number of trials\n",
    "n_trials = 1000\n",
    "study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best parameter settings and reward found\n",
    "best_params = study.best_params\n",
    "best_reward = study.best_value\n",
    "print(f\"Best parameter settings: {best_params}\")\n",
    "print(f\"Best reward: {best_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
